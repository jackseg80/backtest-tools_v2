{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Optimisation Multi-Strat√©gies : Envelope Parameters\n",
    "\n",
    "Ce notebook optimise les **param√®tres de trading** de la strat√©gie multi-envelope :\n",
    "- `ma_base_window` : R√©activit√© du signal\n",
    "- `envelopes` : Distance d'entr√©e\n",
    "- `size` : Risque par trade  \n",
    "- `stop_loss` : Protection\n",
    "\n",
    "**M√©thodologie** : Walk-Forward Optimization avec Expanding Window pour √©viter l'overfitting.\n",
    "\n",
    "**‚ö†Ô∏è Important** : L'optimisation de la d√©tection de r√©gime se fait dans `multi_envelope_adaptive.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuration et chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacks\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports r√©ussis\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm  # Chang√© de tqdm.notebook ‚Üí tqdm.auto\n",
    "\n",
    "# Backtest engine\n",
    "from utilities.strategies.envelopeMulti_v2 import EnvelopeMulti_v2\n",
    "from utilities.data_manager import ExchangeDataManager\n",
    "\n",
    "# Syst√®me adaptatif\n",
    "from core import calculate_regime_series, DEFAULT_PARAMS\n",
    "from core.params_adapter import FixedParamsAdapter, RegimeBasedAdapter\n",
    "from core.backtest_comparator import BacktestComparator\n",
    "\n",
    "# Config plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ======================\n# CONFIGURATION GLOBALE\n# ======================\n\nBACKTEST_LEVERAGE = 10\nINITIAL_WALLET = 1000\nEXCHANGE = \"binance\"\n\n# P√©riodes (Expanding Window)\nPERIODS = {\n    \"train_full\": {\"start\": \"2022-01-01\", \"end\": \"2024-06-30\"},  # Optimisation\n    \"holdout\": {\"start\": \"2024-07-01\", \"end\": \"2024-12-31\"},     # Validation finale (intouchable)\n}\n\n# Walk-Forward Folds (Expanding Window)\nWF_FOLDS = [\n    {\"train_start\": \"2022-01-01\", \"train_end\": \"2022-12-31\", \"test_start\": \"2023-01-01\", \"test_end\": \"2023-06-30\", \"name\": \"Fold1_Bear‚ÜíRecovery\"},\n    {\"train_start\": \"2022-01-01\", \"train_end\": \"2023-06-30\", \"test_start\": \"2023-07-01\", \"test_end\": \"2023-12-31\", \"name\": \"Fold2_Bear+Recovery‚ÜíBull\"},\n    {\"train_start\": \"2022-01-01\", \"train_end\": \"2023-12-31\", \"test_start\": \"2024-01-01\", \"test_end\": \"2024-06-30\", \"name\": \"Fold3_Full‚ÜíBull\"},\n]\n\n# √âchantillon stratifi√© de 8 paires repr√©sentatives\n# (couvre majors, mid-caps, volatiles, low performers)\nPAIRS = [\n    \"BTC/USDT:USDT\",   # Major\n    \"ETH/USDT:USDT\",   # Major\n    \"SOL/USDT:USDT\",   # Mid-cap\n    \"AVAX/USDT:USDT\",  # Mid-cap\n    \"ADA/USDT:USDT\",   # Mid-cap\n    \"DOGE/USDT:USDT\",  # Volatile\n    \"SUSHI/USDT:USDT\", # Volatile (meilleur performer historique)\n    \"TRX/USDT:USDT\",   # Low performer\n]\n\n# Classification par profil\nPAIR_CLASSES = {\n    \"BTC/USDT:USDT\": \"major\",\n    \"ETH/USDT:USDT\": \"major\",\n    \"SOL/USDT:USDT\": \"mid-cap\",\n    \"AVAX/USDT:USDT\": \"mid-cap\",\n    \"ADA/USDT:USDT\": \"mid-cap\",\n    \"DOGE/USDT:USDT\": \"volatile\",\n    \"SUSHI/USDT:USDT\": \"volatile\",\n    \"TRX/USDT:USDT\": \"low\",\n}\n\n# Param√®tres de backtest communs\nBACKTEST_PARAMS = {\n    \"initial_wallet\": INITIAL_WALLET,\n    \"leverage\": BACKTEST_LEVERAGE,\n    \"maker_fee\": 0.0002,\n    \"taker_fee\": 0.0006,\n    \"reinvest\": True,\n    \"liquidation\": True,\n    \"risk_mode\": \"scaling\",\n}\n\nprint(f\"‚úÖ Configuration charg√©e\")\nprint(f\"   Paires: {len(PAIRS)} (√©chantillon stratifi√©)\")\nprint(f\"   - Majors: {sum(1 for c in PAIR_CLASSES.values() if c == 'major')}\")\nprint(f\"   - Mid-caps: {sum(1 for c in PAIR_CLASSES.values() if c == 'mid-cap')}\")\nprint(f\"   - Volatiles: {sum(1 for c in PAIR_CLASSES.values() if c == 'volatile')}\")\nprint(f\"   - Low performers: {sum(1 for c in PAIR_CLASSES.values() if c == 'low')}\")\nprint(f\"   Walk-Forward Folds: {len(WF_FOLDS)}\")\nprint(f\"   Hold-out: {PERIODS['holdout']['start']} ‚Üí {PERIODS['holdout']['end']}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Chargement des donn√©es\nexchange = ExchangeDataManager(\n    exchange_name=EXCHANGE,\n    path_download=\"../database/exchanges\"  # Pointe vers Backtest-Tools-V2/database/exchanges\n)\n\n# Charger TOUTES les donn√©es n√©cessaires (2022-2024)\nstart_date = \"2022-01-01\"\nend_date = \"2024-12-31\"\n\ndf_list_full = {}\nprint(\"üì• Chargement des donn√©es...\")\nfor pair in tqdm(PAIRS, desc=\"Paires\"):\n    df = exchange.load_data(pair, \"1h\", start_date=start_date, end_date=end_date)\n    df_list_full[pair] = df\n\n# BTC pour d√©tection de r√©gime\ndf_btc_full = exchange.load_data(\"BTC/USDT:USDT\", \"1h\", start_date=start_date, end_date=end_date)\n\noldest_pair = min(df_list_full, key=lambda p: df_list_full[p].index.min())\n\nprint(f\"\\n‚úÖ Donn√©es charg√©es\")\nprint(f\"   P√©riode: {start_date} ‚Üí {end_date}\")\nprint(f\"   Paire la plus ancienne: {oldest_pair}\")\nprint(f\"   Nombre de barres: {len(df_list_full[oldest_pair])}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Comparaison manuelle de configurations pr√©-d√©finies\n",
    "\n",
    "Teste 5 configurations fixes pour comprendre l'impact des param√®tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations pr√©-d√©finies\n",
    "MANUAL_CONFIGS = {\n",
    "    \"Conservative\": {\n",
    "        \"ma_base_window\": 10,\n",
    "        \"envelopes\": [0.05, 0.08, 0.12],\n",
    "        \"size\": 0.06,\n",
    "        \"stop_loss\": 0.20,\n",
    "    },\n",
    "    \"Standard (Live actuel)\": {\n",
    "        \"ma_base_window\": 7,\n",
    "        \"envelopes\": [0.07, 0.10, 0.15],\n",
    "        \"size\": 0.10,\n",
    "        \"stop_loss\": 0.25,\n",
    "    },\n",
    "    \"Aggressive\": {\n",
    "        \"ma_base_window\": 5,\n",
    "        \"envelopes\": [0.09, 0.13, 0.18],\n",
    "        \"size\": 0.12,\n",
    "        \"stop_loss\": 0.30,\n",
    "    },\n",
    "    \"Wide Envelopes\": {\n",
    "        \"ma_base_window\": 7,\n",
    "        \"envelopes\": [0.10, 0.15, 0.20],\n",
    "        \"size\": 0.08,\n",
    "        \"stop_loss\": 0.25,\n",
    "    },\n",
    "    \"Tight Envelopes\": {\n",
    "        \"ma_base_window\": 7,\n",
    "        \"envelopes\": [0.05, 0.07, 0.10],\n",
    "        \"size\": 0.08,\n",
    "        \"stop_loss\": 0.25,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"üìã {len(MANUAL_CONFIGS)} configurations manuelles d√©finies\")\n",
    "for name, cfg in MANUAL_CONFIGS.items():\n",
    "    print(f\"   - {name}: MA={cfg['ma_base_window']}, Env={cfg['envelopes']}, Size={cfg['size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction helper pour run un backtest\n",
    "def run_single_backtest(df_list, oldest_pair, params_coin, stop_loss, params_adapter=None):\n",
    "    \"\"\"\n",
    "    Ex√©cute un backtest avec les param√®tres donn√©s.\n",
    "    \n",
    "    Returns:\n",
    "        dict: R√©sultat du backtest (trades, days, wallet, metrics)\n",
    "    \"\"\"\n",
    "    strategy = EnvelopeMulti_v2(\n",
    "        df_list=df_list,\n",
    "        oldest_pair=oldest_pair,\n",
    "        type=[\"long\", \"short\"],\n",
    "        params=params_coin\n",
    "    )\n",
    "    \n",
    "    strategy.populate_indicators()\n",
    "    strategy.populate_buy_sell()\n",
    "    \n",
    "    result = strategy.run_backtest(\n",
    "        **BACKTEST_PARAMS,\n",
    "        stop_loss=stop_loss,\n",
    "        params_adapter=params_adapter\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Fonction run_single_backtest d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer les r√©gimes sur TOUTE la p√©riode (pour comparaison manuelle seulement)\n",
    "# ‚ö†Ô∏è Pour Walk-Forward, on recalculera par fold\n",
    "regime_series_full = calculate_regime_series(df_btc_full, confirm_n=12)\n",
    "\n",
    "print(\"üìä Distribution des r√©gimes (2022-2024):\")\n",
    "regime_counts = regime_series_full.value_counts(normalize=True) * 100\n",
    "for regime, pct in regime_counts.items():\n",
    "    print(f\"   {regime.name}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison manuelle : Fixed vs Adaptive pour chaque config\n",
    "comparator_manual = BacktestComparator(initial_wallet=INITIAL_WALLET)\n",
    "\n",
    "print(\"\\nüöÄ Ex√©cution des backtests manuels (Fixed + Adaptive)...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for config_name, config in tqdm(MANUAL_CONFIGS.items(), desc=\"Configurations\"):\n",
    "    # Pr√©parer params_coin\n",
    "    params_coin = {}\n",
    "    for pair in PAIRS:\n",
    "        params_coin[pair] = {\n",
    "            \"src\": \"close\",\n",
    "            \"ma_base_window\": config[\"ma_base_window\"],\n",
    "            \"envelopes\": config[\"envelopes\"],\n",
    "            \"size\": config[\"size\"] / BACKTEST_LEVERAGE\n",
    "        }\n",
    "    \n",
    "    # 1. Fixed params\n",
    "    adapter_fixed = FixedParamsAdapter(params_coin)\n",
    "    result_fixed = run_single_backtest(\n",
    "        df_list_full, oldest_pair, params_coin, \n",
    "        config[\"stop_loss\"], adapter_fixed\n",
    "    )\n",
    "    \n",
    "    comparator_manual.add_backtest(\n",
    "        name=f\"{config_name} (Fixed)\",\n",
    "        df_trades=result_fixed['trades'],\n",
    "        df_days=result_fixed['days'],\n",
    "        metadata={\"config\": config, \"adaptive\": False}\n",
    "    )\n",
    "    \n",
    "    # 2. Adaptive params\n",
    "    adapter_adaptive = RegimeBasedAdapter(\n",
    "        base_params=params_coin,\n",
    "        regime_series=regime_series_full,\n",
    "        regime_params=DEFAULT_PARAMS,\n",
    "        multipliers={'envelope_std': True},\n",
    "        base_std=0.10\n",
    "    )\n",
    "    result_adaptive = run_single_backtest(\n",
    "        df_list_full, oldest_pair, params_coin,\n",
    "        config[\"stop_loss\"], adapter_adaptive\n",
    "    )\n",
    "    \n",
    "    comparator_manual.add_backtest(\n",
    "        name=f\"{config_name} (Adaptive)\",\n",
    "        df_trades=result_adaptive['trades'],\n",
    "        df_days=result_adaptive['days'],\n",
    "        metadata={\"config\": config, \"adaptive\": True}\n",
    "    )\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Backtests manuels termin√©s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les r√©sultats\n",
    "comparator_manual.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les r√©sultats manuels\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "comparator_manual.save_comparison(f\"results_manual_{timestamp}.csv\")\n",
    "print(f\"üíæ R√©sultats sauvegard√©s: results_manual_{timestamp}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Walk-Forward Optimization (Grid Search)\n",
    "\n",
    "Teste toutes les combinaisons de param√®tres avec validation robuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid de param√®tres (Phase 1 : grossier)\n",
    "PARAM_GRID = {\n",
    "    \"ma_base_window\": [5, 7, 10],\n",
    "    \"envelope_sets\": [\n",
    "        [0.07, 0.10, 0.15],  # Standard\n",
    "        [0.08, 0.12, 0.16],  # Large\n",
    "    ],\n",
    "    \"size\": [0.08, 0.10],\n",
    "    \"stop_loss\": [0.20, 0.25],\n",
    "}\n",
    "\n",
    "# G√©n√©rer toutes les combinaisons\n",
    "grid_combinations = list(product(\n",
    "    PARAM_GRID[\"ma_base_window\"],\n",
    "    PARAM_GRID[\"envelope_sets\"],\n",
    "    PARAM_GRID[\"size\"],\n",
    "    PARAM_GRID[\"stop_loss\"]\n",
    "))\n",
    "\n",
    "print(f\"üîç Grid Search Phase 1 (Coarse)\")\n",
    "print(f\"   Combinaisons: {len(grid_combinations)}\")\n",
    "print(f\"   Walk-Forward Folds: {len(WF_FOLDS)}\")\n",
    "print(f\"   Total backtests: {len(grid_combinations) * len(WF_FOLDS) * 2} (fixed + adaptive)\")\n",
    "print(f\"   Temps estim√©: ~{len(grid_combinations) * len(WF_FOLDS) * 2 * 10 / 60:.0f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour filtrer DataFrame par dates\n",
    "def filter_df_by_dates(df, start_date, end_date):\n",
    "    \"\"\"Filtre un DataFrame par dates.\"\"\"\n",
    "    mask = (df.index >= pd.Timestamp(start_date)) & (df.index <= pd.Timestamp(end_date))\n",
    "    return df[mask]\n",
    "\n",
    "def filter_df_list_by_dates(df_list, start_date, end_date):\n",
    "    \"\"\"Filtre un dict de DataFrames par dates.\"\"\"\n",
    "    return {pair: filter_df_by_dates(df, start_date, end_date) for pair, df in df_list.items()}\n",
    "\n",
    "print(\"‚úÖ Fonctions de filtrage d√©finies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul du score composite anti-overfitting\n",
    "def calculate_composite_score(bt_result, train_sharpe=None):\n",
    "    \"\"\"\n",
    "    Calcule le score composite pour √©valuer une configuration.\n",
    "    \n",
    "    Args:\n",
    "        bt_result: R√©sultat du backtest\n",
    "        train_sharpe: Sharpe du train (pour consistency), None si on calcule train\n",
    "    \n",
    "    Returns:\n",
    "        float: Score composite (plus √©lev√© = meilleur)\n",
    "    \"\"\"\n",
    "    df_trades = bt_result['trades']\n",
    "    df_days = bt_result['days']\n",
    "    \n",
    "    # Calculer m√©triques de base\n",
    "    n_trades = len(df_trades)\n",
    "    \n",
    "    # Filtre: trop peu de trades = pas fiable\n",
    "    if n_trades < 30:\n",
    "        return -999\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe = bt_result.get('sharpe_ratio', 0)\n",
    "    if pd.isna(sharpe) or np.isinf(sharpe):\n",
    "        sharpe = 0\n",
    "    \n",
    "    # Max Drawdown\n",
    "    df_days_copy = df_days.copy()\n",
    "    df_days_copy['cummax'] = df_days_copy['wallet'].cummax()\n",
    "    df_days_copy['drawdown_pct'] = (df_days_copy['wallet'] - df_days_copy['cummax']) / df_days_copy['cummax']\n",
    "    max_dd = abs(df_days_copy['drawdown_pct'].min()) * 100\n",
    "    \n",
    "    # Calmar Ratio (return / max_dd)\n",
    "    final_wallet = df_days['wallet'].iloc[-1]\n",
    "    total_return = (final_wallet / INITIAL_WALLET - 1) * 100\n",
    "    calmar = total_return / max(max_dd, 1.0)  # √âviter division par 0\n",
    "    \n",
    "    # Win Rate\n",
    "    df_trades_copy = df_trades.copy()\n",
    "    if 'trade_result' not in df_trades_copy.columns:\n",
    "        df_trades_copy['trade_result'] = (\n",
    "            df_trades_copy[\"close_trade_size\"] -\n",
    "            df_trades_copy[\"open_trade_size\"] -\n",
    "            df_trades_copy[\"open_fee\"] -\n",
    "            df_trades_copy[\"close_fee\"]\n",
    "        )\n",
    "    win_rate = (df_trades_copy['trade_result'] > 0).mean()\n",
    "    \n",
    "    # Profit Factor\n",
    "    gross_profit = df_trades_copy[df_trades_copy['trade_result'] > 0]['trade_result'].sum()\n",
    "    gross_loss = abs(df_trades_copy[df_trades_copy['trade_result'] < 0]['trade_result'].sum())\n",
    "    profit_factor = gross_profit / max(gross_loss, 1.0) if gross_loss > 0 else gross_profit\n",
    "    profit_factor_normalized = min(profit_factor / 2, 1)  # Cap √† 1\n",
    "    \n",
    "    # Consistency (train vs test)\n",
    "    if train_sharpe is not None:\n",
    "        consistency = 1 - abs(train_sharpe - sharpe) / max(0.1, abs(train_sharpe))\n",
    "        consistency = max(0, consistency)  # Clamp √† 0\n",
    "    else:\n",
    "        consistency = 0  # Pas de consistency pour train\n",
    "    \n",
    "    # Score composite\n",
    "    if train_sharpe is None:  # Train\n",
    "        score = (\n",
    "            sharpe * 0.35 +\n",
    "            calmar * 0.25 +\n",
    "            (1 - min(max_dd, 100) / 100) * 0.20 +\n",
    "            win_rate * 0.10 +\n",
    "            profit_factor_normalized * 0.10\n",
    "        )\n",
    "    else:  # Test\n",
    "        score = (\n",
    "            sharpe * 0.30 +\n",
    "            consistency * 0.25 +\n",
    "            calmar * 0.20 +\n",
    "            (1 - min(max_dd, 100) / 100) * 0.15 +\n",
    "            win_rate * 0.05 +\n",
    "            profit_factor_normalized * 0.05\n",
    "        )\n",
    "    \n",
    "    return score\n",
    "\n",
    "print(\"‚úÖ Fonction calculate_composite_score d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-Forward Optimization Loop\n",
    "wf_results = []\n",
    "\n",
    "print(\"\\nüöÄ D√©marrage Walk-Forward Optimization...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_iterations = len(WF_FOLDS) * len(grid_combinations) * 2  # √ó 2 pour fixed + adaptive\n",
    "pbar = tqdm(total=total_iterations, desc=\"Walk-Forward Progress\")\n",
    "\n",
    "for fold in WF_FOLDS:\n",
    "    fold_name = fold[\"name\"]\n",
    "    print(f\"\\nüìÇ {fold_name}\")\n",
    "    print(f\"   Train: {fold['train_start']} ‚Üí {fold['train_end']}\")\n",
    "    print(f\"   Test:  {fold['test_start']} ‚Üí {fold['test_end']}\")\n",
    "    \n",
    "    # Filtrer donn√©es par p√©riode\n",
    "    df_list_train = filter_df_list_by_dates(df_list_full, fold['train_start'], fold['train_end'])\n",
    "    df_list_test = filter_df_list_by_dates(df_list_full, fold['test_start'], fold['test_end'])\n",
    "    \n",
    "    df_btc_train = filter_df_by_dates(df_btc_full, fold['train_start'], fold['train_end'])\n",
    "    df_btc_test = filter_df_by_dates(df_btc_full, fold['test_start'], fold['test_end'])\n",
    "    \n",
    "    # ‚ö†Ô∏è IMPORTANT: Calculer r√©gimes par fold (√©vite lookahead bias)\n",
    "    regime_train = calculate_regime_series(df_btc_train, confirm_n=12)\n",
    "    regime_test = calculate_regime_series(df_btc_test, confirm_n=12)\n",
    "    \n",
    "    for combo_idx, (ma_window, envelopes, size, stop_loss) in enumerate(grid_combinations):\n",
    "        # Pr√©parer params_coin\n",
    "        params_coin = {}\n",
    "        for pair in PAIRS:\n",
    "            params_coin[pair] = {\n",
    "                \"src\": \"close\",\n",
    "                \"ma_base_window\": ma_window,\n",
    "                \"envelopes\": envelopes,\n",
    "                \"size\": size / BACKTEST_LEVERAGE\n",
    "            }\n",
    "        \n",
    "        # === TRAIN ===\n",
    "        # 1. Fixed\n",
    "        adapter_fixed = FixedParamsAdapter(params_coin)\n",
    "        bt_train_fixed = run_single_backtest(\n",
    "            df_list_train, oldest_pair, params_coin, stop_loss, adapter_fixed\n",
    "        )\n",
    "        score_train_fixed = calculate_composite_score(bt_train_fixed)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # 2. Adaptive\n",
    "        adapter_adaptive_train = RegimeBasedAdapter(\n",
    "            base_params=params_coin,\n",
    "            regime_series=regime_train,\n",
    "            regime_params=DEFAULT_PARAMS,\n",
    "            multipliers={'envelope_std': True},\n",
    "            base_std=0.10\n",
    "        )\n",
    "        bt_train_adaptive = run_single_backtest(\n",
    "            df_list_train, oldest_pair, params_coin, stop_loss, adapter_adaptive_train\n",
    "        )\n",
    "        score_train_adaptive = calculate_composite_score(bt_train_adaptive)\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # === TEST ===\n",
    "        # 1. Fixed\n",
    "        adapter_fixed_test = FixedParamsAdapter(params_coin)\n",
    "        bt_test_fixed = run_single_backtest(\n",
    "            df_list_test, oldest_pair, params_coin, stop_loss, adapter_fixed_test\n",
    "        )\n",
    "        sharpe_train_fixed = bt_train_fixed.get('sharpe_ratio', 0)\n",
    "        score_test_fixed = calculate_composite_score(bt_test_fixed, sharpe_train_fixed)\n",
    "        \n",
    "        # 2. Adaptive\n",
    "        adapter_adaptive_test = RegimeBasedAdapter(\n",
    "            base_params=params_coin,\n",
    "            regime_series=regime_test,\n",
    "            regime_params=DEFAULT_PARAMS,\n",
    "            multipliers={'envelope_std': True},\n",
    "            base_std=0.10\n",
    "        )\n",
    "        bt_test_adaptive = run_single_backtest(\n",
    "            df_list_test, oldest_pair, params_coin, stop_loss, adapter_adaptive_test\n",
    "        )\n",
    "        sharpe_train_adaptive = bt_train_adaptive.get('sharpe_ratio', 0)\n",
    "        score_test_adaptive = calculate_composite_score(bt_test_adaptive, sharpe_train_adaptive)\n",
    "        \n",
    "        # Stocker r√©sultats\n",
    "        wf_results.append({\n",
    "            \"fold\": fold_name,\n",
    "            \"combo_idx\": combo_idx,\n",
    "            \"ma_window\": ma_window,\n",
    "            \"envelopes\": str(envelopes),\n",
    "            \"size\": size,\n",
    "            \"stop_loss\": stop_loss,\n",
    "            \"adaptive\": False,\n",
    "            \"train_wallet\": bt_train_fixed['wallet'],\n",
    "            \"train_sharpe\": sharpe_train_fixed,\n",
    "            \"train_score\": score_train_fixed,\n",
    "            \"train_trades\": len(bt_train_fixed['trades']),\n",
    "            \"test_wallet\": bt_test_fixed['wallet'],\n",
    "            \"test_sharpe\": bt_test_fixed.get('sharpe_ratio', 0),\n",
    "            \"test_score\": score_test_fixed,\n",
    "            \"test_trades\": len(bt_test_fixed['trades']),\n",
    "        })\n",
    "        \n",
    "        wf_results.append({\n",
    "            \"fold\": fold_name,\n",
    "            \"combo_idx\": combo_idx,\n",
    "            \"ma_window\": ma_window,\n",
    "            \"envelopes\": str(envelopes),\n",
    "            \"size\": size,\n",
    "            \"stop_loss\": stop_loss,\n",
    "            \"adaptive\": True,\n",
    "            \"train_wallet\": bt_train_adaptive['wallet'],\n",
    "            \"train_sharpe\": sharpe_train_adaptive,\n",
    "            \"train_score\": score_train_adaptive,\n",
    "            \"train_trades\": len(bt_train_adaptive['trades']),\n",
    "            \"test_wallet\": bt_test_adaptive['wallet'],\n",
    "            \"test_sharpe\": bt_test_adaptive.get('sharpe_ratio', 0),\n",
    "            \"test_score\": score_test_adaptive,\n",
    "            \"test_trades\": len(bt_test_adaptive['trades']),\n",
    "        })\n",
    "\n",
    "pbar.close()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Walk-Forward Optimization termin√©e\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er DataFrame des r√©sultats\n",
    "df_wf_results = pd.DataFrame(wf_results)\n",
    "\n",
    "# Calculer moyenne des scores sur les folds\n",
    "df_wf_avg = df_wf_results.groupby(['combo_idx', 'ma_window', 'envelopes', 'size', 'stop_loss', 'adaptive']).agg({\n",
    "    'train_score': 'mean',\n",
    "    'test_score': 'mean',\n",
    "    'train_sharpe': 'mean',\n",
    "    'test_sharpe': 'mean',\n",
    "    'train_trades': 'sum',\n",
    "    'test_trades': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# Calculer consistency\n",
    "df_wf_avg['consistency'] = 1 - abs(df_wf_avg['train_sharpe'] - df_wf_avg['test_sharpe']) / df_wf_avg['train_sharpe'].abs().clip(lower=0.1)\n",
    "df_wf_avg['consistency'] = df_wf_avg['consistency'].clip(lower=0)\n",
    "\n",
    "# Score final = moyenne test_score\n",
    "df_wf_avg = df_wf_avg.sort_values('test_score', ascending=False)\n",
    "\n",
    "print(\"‚úÖ R√©sultats agr√©g√©s\")\n",
    "print(f\"   Total configurations test√©es: {len(df_wf_avg)}\")\n",
    "print(f\"   Folds par configuration: {len(WF_FOLDS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 configurations\n",
    "print(\"\\nüèÜ TOP 10 CONFIGURATIONS (par Test Score moyen)\\n\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "top10 = df_wf_avg.head(10)\n",
    "for idx, row in top10.iterrows():\n",
    "    print(f\"#{idx+1}\")\n",
    "    print(f\"   MA: {row['ma_window']}, Env: {row['envelopes']}, Size: {row['size']}, SL: {row['stop_loss']}, Adaptive: {row['adaptive']}\")\n",
    "    print(f\"   Train Sharpe: {row['train_sharpe']:.2f}, Test Sharpe: {row['test_sharpe']:.2f}, Consistency: {row['consistency']:.2f}\")\n",
    "    print(f\"   Train Score: {row['train_score']:.3f}, Test Score: {row['test_score']:.3f}\")\n",
    "    print(f\"   Trades: Train={row['train_trades']}, Test={row['test_trades']}\")\n",
    "    print()\n",
    "\n",
    "# Identifier le meilleur\n",
    "best_config = top10.iloc[0]\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(f\"‚úÖ MEILLEURE CONFIGURATION:\")\n",
    "print(f\"   MA: {best_config['ma_window']}\")\n",
    "print(f\"   Envelopes: {best_config['envelopes']}\")\n",
    "print(f\"   Size: {best_config['size']}\")\n",
    "print(f\"   Stop Loss: {best_config['stop_loss']}\")\n",
    "print(f\"   Adaptive: {best_config['adaptive']}\")\n",
    "print(f\"   Test Score: {best_config['test_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Comparaison Phase A (8 paires) vs Phase B (28 paires)\nprint(\"üìä COMPARAISON PHASE A vs PHASE B\")\nprint(\"=\" * 80)\n\nfor idx, row_portfolio in df_portfolio.iterrows():\n    config_idx = int(row_portfolio['config'].replace('Config#', '')) - 1\n    row_phase_a = top3.iloc[config_idx]\n    \n    print(f\"\\n{row_portfolio['config']}:\")\n    print(f\"   MA={row_portfolio['ma_window']}, Env={row_portfolio['envelopes']}, Adaptive={row_portfolio['adaptive']}\")\n    print(f\"   Phase A (8 paires):  Score={row_phase_a['test_score']:.3f}, Sharpe={row_phase_a['test_sharpe']:.2f}\")\n    print(f\"   Phase B (28 paires): Score={row_portfolio['score']:.3f}, Sharpe={row_portfolio['sharpe']:.2f}\")\n    \n    # V√©rifier consistency\n    score_diff = abs(row_portfolio['score'] - row_phase_a['test_score'])\n    sharpe_diff = abs(row_portfolio['sharpe'] - row_phase_a['test_sharpe'])\n    \n    if sharpe_diff <= 0.5:\n        print(f\"   ‚úÖ ROBUSTE: Sharpe diff = {sharpe_diff:.2f} (‚â§0.5)\")\n    else:\n        print(f\"   ‚ö†Ô∏è  DIVERGENCE: Sharpe diff = {sharpe_diff:.2f} (>0.5)\")\n\n# S√©lectionner la meilleure config pour hold-out\nbest_config_portfolio = df_portfolio.iloc[0]\n\nprint(\"\\n\" + \"=\" * 80)\nprint(f\"üèÜ MEILLEURE CONFIG POUR HOLD-OUT:\")\nprint(f\"   {best_config_portfolio['config']}\")\nprint(f\"   MA: {best_config_portfolio['ma_window']}\")\nprint(f\"   Envelopes: {best_config_portfolio['envelopes']}\")\nprint(f\"   Size: {best_config_portfolio['size']}\")\nprint(f\"   Stop Loss: {best_config_portfolio['stop_loss']}\")\nprint(f\"   Adaptive: {best_config_portfolio['adaptive']}\")\nprint(f\"   Score Portfolio: {best_config_portfolio['score']:.3f}\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Tester top-3 configs sur 28 paires\ntop3 = df_wf_avg.head(3)\n\nportfolio_results = []\n\nfor idx, row in top3.iterrows():\n    config_name = f\"Config#{idx+1}\"\n    print(f\"\\nüîÑ Test {config_name}: MA={row['ma_window']}, Env={row['envelopes']}, Adaptive={row['adaptive']}\")\n    \n    # Pr√©parer params\n    params_coin_28 = {}\n    for pair in df_list_full_28.keys():\n        params_coin_28[pair] = {\n            \"src\": \"close\",\n            \"ma_base_window\": int(row['ma_window']),\n            \"envelopes\": eval(row['envelopes']),\n            \"size\": float(row['size']) / BACKTEST_LEVERAGE\n        }\n    \n    # Adapter\n    if row['adaptive']:\n        adapter = RegimeBasedAdapter(\n            base_params=params_coin_28,\n            regime_series=regime_series_full_28,\n            regime_params=DEFAULT_PARAMS,\n            multipliers={'envelope_std': True},\n            base_std=0.10\n        )\n    else:\n        adapter = FixedParamsAdapter(params_coin_28)\n    \n    # Run backtest\n    result = run_single_backtest(\n        df_list_full_28, oldest_pair_28, params_coin_28,\n        float(row['stop_loss']), adapter\n    )\n    \n    # M√©triques\n    final_wallet = result['wallet']\n    sharpe = result.get('sharpe_ratio', 0)\n    n_trades = len(result['trades'])\n    \n    # Score composite (comme Phase A)\n    score = calculate_composite_score(result)\n    \n    portfolio_results.append({\n        'config': config_name,\n        'ma_window': int(row['ma_window']),\n        'envelopes': row['envelopes'],\n        'size': float(row['size']),\n        'stop_loss': float(row['stop_loss']),\n        'adaptive': bool(row['adaptive']),\n        'wallet': final_wallet,\n        'sharpe': sharpe,\n        'n_trades': n_trades,\n        'score': score,\n    })\n    \n    print(f\"   Wallet: ${final_wallet:.2f}, Sharpe: {sharpe:.2f}, Trades: {n_trades}, Score: {score:.3f}\")\n\ndf_portfolio = pd.DataFrame(portfolio_results).sort_values('score', ascending=False)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Validation portfolio compl√©t√©e\\n\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Charger donn√©es pour 28 paires\ndf_list_full_28 = {}\nprint(\"\\nüì• Chargement des 28 paires...\")\nfor pair in tqdm(PAIRS_FULL, desc=\"Paires\"):\n    try:\n        df = exchange.load_data(pair, \"1h\", start_date=PERIODS['train_full']['start'], end_date=PERIODS['train_full']['end'])\n        df_list_full_28[pair] = df\n    except FileNotFoundError:\n        print(f\"‚ö†Ô∏è  {pair} non disponible, ignor√©\")\n\noldest_pair_28 = min(df_list_full_28, key=lambda p: df_list_full_28[p].index.min())\n\n# R√©gimes sur BTC (m√™me p√©riode)\ndf_btc_full_28 = exchange.load_data(\"BTC/USDT:USDT\", \"1h\", \n                                     start_date=PERIODS['train_full']['start'], \n                                     end_date=PERIODS['train_full']['end'])\nregime_series_full_28 = calculate_regime_series(df_btc_full_28, confirm_n=12)\n\nprint(f\"\\n‚úÖ {len(df_list_full_28)} paires charg√©es (sur 28 demand√©es)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Paires compl√®tes du live bot (28 paires)\nPAIRS_FULL = [\n    \"BTC/USDT:USDT\", \"ETH/USDT:USDT\", \"BNB/USDT:USDT\", \"SOL/USDT:USDT\",\n    \"XRP/USDT:USDT\", \"DOGE/USDT:USDT\", \"ADA/USDT:USDT\", \"AVAX/USDT:USDT\",\n    \"SHIB/USDT:USDT\", \"DOT/USDT:USDT\", \"LINK/USDT:USDT\", \"MATIC/USDT:USDT\",\n    \"UNI/USDT:USDT\", \"ATOM/USDT:USDT\", \"LTC/USDT:USDT\", \"ETC/USDT:USDT\",\n    \"APT/USDT:USDT\", \"ARB/USDT:USDT\", \"OP/USDT:USDT\", \"NEAR/USDT:USDT\",\n    \"FIL/USDT:USDT\", \"INJ/USDT:USDT\", \"IMX/USDT:USDT\", \"RUNE/USDT:USDT\",\n    \"SUSHI/USDT:USDT\", \"TRX/USDT:USDT\", \"AAVE/USDT:USDT\", \"CRV/USDT:USDT\",\n]\n\nprint(f\"üìä PHASE B - VALIDATION PORTFOLIO COMPLET\")\nprint(\"=\" * 80)\nprint(f\"   Paires: {len(PAIRS_FULL)} (portfolio complet)\")\nprint(f\"   P√©riode: {PERIODS['train_full']['start']} ‚Üí {PERIODS['train_full']['end']}\")\nprint(f\"   Top configs √† tester: 3\")\nprint(f\"\\n‚ö†Ô∏è  Cette phase valide que les configs tiennent sur le portfolio complet\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3.5Ô∏è‚É£ Phase B - Validation Portfolio complet (28 paires)\n\nTeste le **top-3** des configs sur les **28 paires compl√®tes** (m√™me p√©riode train) pour v√©rifier que les r√©sultats tiennent sur le portfolio complet.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Validation Hold-out finale\n",
    "\n",
    "Test **UNE SEULE FOIS** sur les donn√©es de hold-out (2024 H2) pour v√©rifier qu'il n'y a pas d'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n‚ö†Ô∏è  VALIDATION HOLD-OUT FINALE (28 paires)\")\nprint(\"=\" * 80)\nprint(f\"P√©riode: {PERIODS['holdout']['start']} ‚Üí {PERIODS['holdout']['end']}\")\nprint(f\"‚ö†Ô∏è  Cette validation ne peut √™tre ex√©cut√©e qu'UNE SEULE FOIS !\\n\")\n\n# Filtrer donn√©es hold-out (28 paires)\ndf_list_holdout_28 = filter_df_list_by_dates(df_list_full_28, PERIODS['holdout']['start'], PERIODS['holdout']['end'])\ndf_btc_holdout = exchange.load_data(\"BTC/USDT:USDT\", \"1h\", \n                                     start_date=PERIODS['holdout']['start'], \n                                     end_date=PERIODS['holdout']['end'])\nregime_holdout = calculate_regime_series(df_btc_holdout, confirm_n=12)\n\n# Utiliser la meilleure config de Phase B (portfolio complet)\nbest_cfg = best_config_portfolio\n\n# Pr√©parer params pour 28 paires\nparams_coin_holdout = {}\nfor pair in df_list_holdout_28.keys():\n    params_coin_holdout[pair] = {\n        \"src\": \"close\",\n        \"ma_base_window\": int(best_cfg['ma_window']),\n        \"envelopes\": eval(best_cfg['envelopes']) if isinstance(best_cfg['envelopes'], str) else best_cfg['envelopes'],\n        \"size\": float(best_cfg['size']) / BACKTEST_LEVERAGE\n    }\n\n# Test hold-out\nif best_cfg['adaptive']:\n    adapter_holdout = RegimeBasedAdapter(\n        base_params=params_coin_holdout,\n        regime_series=regime_holdout,\n        regime_params=DEFAULT_PARAMS,\n        multipliers={'envelope_std': True},\n        base_std=0.10\n    )\nelse:\n    adapter_holdout = FixedParamsAdapter(params_coin_holdout)\n\nbt_holdout = run_single_backtest(\n    df_list_holdout_28, oldest_pair_28, params_coin_holdout,\n    float(best_cfg['stop_loss']), adapter_holdout\n)\n\n# Calculer m√©triques hold-out\nholdout_sharpe = bt_holdout.get('sharpe_ratio', 0)\nholdout_wallet = bt_holdout['wallet']\nholdout_perf = (holdout_wallet / INITIAL_WALLET - 1) * 100\nholdout_trades = len(bt_holdout['trades'])\n\n# Comparaison avec Phase B (portfolio)\nportfolio_sharpe = best_cfg['sharpe']\n\nprint(f\"\\nüìä R√âSULTATS HOLD-OUT:\")\nprint(f\"   Wallet final: ${holdout_wallet:.2f}\")\nprint(f\"   Performance: {holdout_perf:+.2f}%\")\nprint(f\"   Sharpe Ratio: {holdout_sharpe:.2f}\")\nprint(f\"   Nombre de trades: {holdout_trades}\")\n\nprint(f\"\\nüìä COMPARAISON:\")\nprint(f\"   Phase B Portfolio Sharpe: {portfolio_sharpe:.2f}\")\nprint(f\"   Hold-out Sharpe:          {holdout_sharpe:.2f}\")\n\n# Validation\nsharpe_diff = abs(holdout_sharpe - portfolio_sharpe)\n\nif sharpe_diff <= 0.5:\n    print(f\"\\n‚úÖ VALIDATION R√âUSSIE: Hold-out Sharpe ‚âà Portfolio Sharpe (diff={sharpe_diff:.2f})\")\n    print(f\"   Pas d'overfitting d√©tect√©. Configuration robuste sur 28 paires.\")\nelif sharpe_diff <= 1.0:\n    print(f\"\\n‚ö†Ô∏è  WARNING: Hold-out Sharpe diverge l√©g√®rement (diff={sharpe_diff:.2f})\")\n    print(f\"   Overfitting possible mais acceptable.\")\nelse:\n    print(f\"\\n‚ùå √âCHEC: Hold-out Sharpe diverge fortement (diff={sharpe_diff:.2f})\")\n    print(f\"   Overfitting d√©tect√© ! R√©viser les param√®tres.\")\n\nprint(\"\\n\" + \"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ R√©sultats et visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot : Train Sharpe vs Test Sharpe\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# S√©parer Fixed et Adaptive\n",
    "df_fixed = df_wf_avg[df_wf_avg['adaptive'] == False]\n",
    "df_adaptive = df_wf_avg[df_wf_avg['adaptive'] == True]\n",
    "\n",
    "ax.scatter(df_fixed['train_sharpe'], df_fixed['test_sharpe'], \n",
    "           alpha=0.6, s=100, label='Fixed', marker='o')\n",
    "ax.scatter(df_adaptive['train_sharpe'], df_adaptive['test_sharpe'], \n",
    "           alpha=0.6, s=100, label='Adaptive', marker='^')\n",
    "\n",
    "# Ligne y=x (pas d'overfitting)\n",
    "max_sharpe = max(df_wf_avg['train_sharpe'].max(), df_wf_avg['test_sharpe'].max())\n",
    "min_sharpe = min(df_wf_avg['train_sharpe'].min(), df_wf_avg['test_sharpe'].min())\n",
    "ax.plot([min_sharpe, max_sharpe], [min_sharpe, max_sharpe], \n",
    "        'r--', alpha=0.5, label='No overfitting (y=x)')\n",
    "\n",
    "# Zone acceptable (¬±0.5)\n",
    "ax.fill_between([min_sharpe, max_sharpe], \n",
    "                 [min_sharpe - 0.5, max_sharpe - 0.5],\n",
    "                 [min_sharpe + 0.5, max_sharpe + 0.5],\n",
    "                 alpha=0.1, color='green', label='Acceptable zone (¬±0.5)')\n",
    "\n",
    "ax.set_xlabel('Train Sharpe Ratio', fontsize=12)\n",
    "ax.set_ylabel('Test Sharpe Ratio', fontsize=12)\n",
    "ax.set_title('Train vs Test Sharpe Ratio (Overfitting Detection)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'train_vs_test_sharpe_{timestamp}.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Graphique sauvegard√©: train_vs_test_sharpe_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart : Top 10 configurations par test score\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "top10_display = df_wf_avg.head(10).copy()\n",
    "top10_display['config_label'] = (\n",
    "    'MA=' + top10_display['ma_window'].astype(str) + \n",
    "    ', Size=' + top10_display['size'].astype(str) +\n",
    "    ', ' + top10_display['adaptive'].map({True: 'Adapt', False: 'Fixed'})\n",
    ")\n",
    "\n",
    "x = range(len(top10_display))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar([i - width/2 for i in x], top10_display['train_score'], \n",
    "               width, label='Train Score', alpha=0.8, color='steelblue')\n",
    "bars2 = ax.bar([i + width/2 for i in x], top10_display['test_score'], \n",
    "               width, label='Test Score', alpha=0.8, color='coral')\n",
    "\n",
    "ax.set_xlabel('Configuration', fontsize=12)\n",
    "ax.set_ylabel('Composite Score', fontsize=12)\n",
    "ax.set_title('Top 10 Configurations by Test Score', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top10_display['config_label'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'top10_scores_{timestamp}.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Graphique sauvegard√©: top10_scores_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder tous les r√©sultats\n",
    "df_wf_results.to_csv(f\"wf_results_detailed_{timestamp}.csv\", index=False)\n",
    "df_wf_avg.to_csv(f\"wf_results_summary_{timestamp}.csv\", index=False)\n",
    "\n",
    "# Sauvegarder meilleure config en JSON\n",
    "import json\n",
    "\n",
    "best_config_export = {\n",
    "    \"ma_base_window\": int(best_config['ma_window']),\n",
    "    \"envelopes\": eval(best_config['envelopes']),\n",
    "    \"size\": float(best_config['size']),\n",
    "    \"stop_loss\": float(best_config['stop_loss']),\n",
    "    \"adaptive\": bool(best_config['adaptive']),\n",
    "    \"train_sharpe\": float(best_config['train_sharpe']),\n",
    "    \"test_sharpe\": float(best_config['test_sharpe']),\n",
    "    \"test_score\": float(best_config['test_score']),\n",
    "    \"holdout_sharpe\": float(holdout_sharpe),\n",
    "    \"holdout_perf\": float(holdout_perf),\n",
    "    \"timestamp\": timestamp,\n",
    "}\n",
    "\n",
    "with open(f\"best_config_{timestamp}.json\", 'w') as f:\n",
    "    json.dump(best_config_export, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ R√©sultats sauvegard√©s:\")\n",
    "print(f\"   - wf_results_detailed_{timestamp}.csv (tous les backtests)\")\n",
    "print(f\"   - wf_results_summary_{timestamp}.csv (moyennes par config)\")\n",
    "print(f\"   - best_config_{timestamp}.json (meilleure configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Recommandation finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\" * 80)\nprint(\"üéØ RECOMMANDATION FINALE\")\nprint(\"=\" * 80)\n\nprint(f\"\\n‚úÖ Meilleure configuration identifi√©e (valid√©e sur 28 paires):\")\nprint(f\"   Config: {best_config_portfolio['config']}\")\nprint(f\"   ma_base_window: {best_config_portfolio['ma_window']}\")\nprint(f\"   envelopes: {best_config_portfolio['envelopes']}\")\nprint(f\"   size: {best_config_portfolio['size']}\")\nprint(f\"   stop_loss: {best_config_portfolio['stop_loss']}\")\nprint(f\"   adaptive: {best_config_portfolio['adaptive']}\")\n\nprint(f\"\\nüìä Performance valid√©e:\")\nprint(f\"   Phase A (8 paires) - Test Score: {top3.iloc[0]['test_score']:.3f}, Sharpe: {top3.iloc[0]['test_sharpe']:.2f}\")\nprint(f\"   Phase B (28 paires) - Score: {best_config_portfolio['score']:.3f}, Sharpe: {best_config_portfolio['sharpe']:.2f}\")\nprint(f\"   Hold-out (28 paires) - Sharpe: {holdout_sharpe:.2f}, Perf: {holdout_perf:+.2f}%\")\n\nif sharpe_diff <= 0.5:\n    print(f\"\\n‚úÖ Validation: Configuration robuste (pas d'overfitting)\")\n    print(f\"   ‚úì Test√©e sur 8 paires (Walk-Forward)\")\n    print(f\"   ‚úì Valid√©e sur 28 paires (Phase B)\")\n    print(f\"   ‚úì Hold-out confirm√© (2024-H2)\")\n    print(f\"   ‚Üí RECOMMAND√â pour mise en production\")\nelif sharpe_diff <= 1.0:\n    print(f\"\\n‚ö†Ô∏è  Validation: Overfitting l√©ger d√©tect√©\")\n    print(f\"   ‚Üí Utiliser avec prudence, surveiller en live\")\nelse:\n    print(f\"\\n‚ùå Validation: Overfitting significatif\")\n    print(f\"   ‚Üí NE PAS utiliser en production\")\n    print(f\"   ‚Üí R√©duire la complexit√© du grid ou augmenter les donn√©es\")\n\nprint(f\"\\nüìù Prochaines √©tapes:\")\nprint(f\"   1. Appliquer la config dans multi_envelope.ipynb (28 paires)\")\nprint(f\"   2. Valider sur paper trading / forward test\")\nprint(f\"   3. Si r√©sultats conformes ‚Üí D√©ployer en production\")\n\nprint(f\"\\nüí° Note:\")\nprint(f\"   Cette config a √©t√© optimis√©e sur un √©chantillon stratifi√© (8 paires)\")\nprint(f\"   puis valid√©e sur le portfolio complet (28 paires) + hold-out.\")\nprint(f\"   M√©thodologie robuste anti-overfitting.\")\n\nprint(\"\\n\" + \"=\" * 80)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}