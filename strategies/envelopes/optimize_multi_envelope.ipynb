{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî¨ Optimisation Multi-Strat√©gies : Envelope Parameters\n",
    "\n",
    "Ce notebook optimise les **param√®tres de trading** de la strat√©gie multi-envelope :\n",
    "- `ma_base_window` : R√©activit√© du signal\n",
    "- `envelopes` : Distance d'entr√©e\n",
    "- `size` : Risque par trade  \n",
    "- `stop_loss` : Protection\n",
    "\n",
    "**M√©thodologie** : Walk-Forward Optimization avec Expanding Window pour √©viter l'overfitting.\n",
    "\n",
    "**‚ö†Ô∏è Important** : L'optimisation de la d√©tection de r√©gime se fait dans `multi_envelope_adaptive.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuration et chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacks\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Module optimized_worker charg√© (numpy views + m√©moire optimis√©e)\n",
      "‚úÖ Mapping nb envelopes charg√© : 28 pairs\n",
      "   4 envelopes : 7 pairs\n",
      "   3 envelopes : 21 pairs\n",
      "‚úÖ Imports r√©ussis (multi-core activ√©)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed  # Pour multi-core\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "from indicator_cache import IndicatorCache, precompute_all_indicators\n",
    "from optimized_worker import prepare_data_for_worker\n",
    "\n",
    "# Backtest engine\n",
    "from utilities.strategies.envelopeMulti_v2 import EnvelopeMulti_v2\n",
    "from utilities.data_manager import ExchangeDataManager\n",
    "\n",
    "# Syst√®me adaptatif\n",
    "from core import calculate_regime_series, DEFAULT_PARAMS\n",
    "from core.params_adapter import FixedParamsAdapter, RegimeBasedAdapter\n",
    "from core.backtest_comparator import BacktestComparator\n",
    "\n",
    "# === ETAPE 2A : CHARGEMENT MAPPING NB ENVELOPES ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "envelope_mapping_path = 'envelope_count_mapping.csv'  # M√™me dossier que le notebook\n",
    "\n",
    "if os.path.exists(envelope_mapping_path):\n",
    "    df_envelope_mapping = pd.read_csv(envelope_mapping_path, index_col='pair')\n",
    "    print(f\"‚úÖ Mapping nb envelopes charg√© : {len(df_envelope_mapping)} pairs\")\n",
    "    print(f\"   4 envelopes : {(df_envelope_mapping['n_envelopes'] == 4).sum()} pairs\")\n",
    "    print(f\"   3 envelopes : {(df_envelope_mapping['n_envelopes'] == 3).sum()} pairs\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  WARNING: envelope_count_mapping.csv non trouv√©\")\n",
    "    print(\"   Ex√©cutez d'abord : python assign_envelope_count.py\")\n",
    "    df_envelope_mapping = None\n",
    "\n",
    "# Config plotting\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis (multi-core activ√©)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e\n",
      "   üß™ MODE TEST RAPIDE\n",
      "   Folds: 2 (au lieu de 7)\n",
      "   Paires: 4 (au lieu de 8)\n",
      "   - Majors: 1\n",
      "   - Mid-caps: 1\n",
      "   - Volatiles: 1\n",
      "   - Low performers: 1\n",
      "   Walk-Forward Folds: 2\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# CONFIGURATION GLOBALE\n",
    "# ======================\n",
    "\n",
    "BACKTEST_LEVERAGE = 10\n",
    "INITIAL_WALLET = 1000\n",
    "EXCHANGE = \"binance\"\n",
    "TEST_MODE = True\n",
    "\n",
    "# P√©riodes (Expanding Window)\n",
    "# Couvre tous les cycles: BULL 2020-2021, BEAR 2022, RECOVERY 2023, BULL 2024, BULL 2025\n",
    "PERIODS = {\n",
    "    \"train_full\": {\"start\": \"2020-01-01\", \"end\": \"2025-06-30\"},  # Optimisation (toute la p√©riode sauf 3 mois)\n",
    "    \"holdout\": {\"start\": \"2025-07-01\", \"end\": \"2025-10-03\"},     # Validation finale (3 derniers mois)\n",
    "}\n",
    "\n",
    "# Walk-Forward Folds (Expanding Window)\n",
    "if TEST_MODE:\n",
    "    # üß™ MODE TEST : 2 folds uniquement (donn√©es 2024-2025)\n",
    "    WF_FOLDS = [\n",
    "        {\"train_start\": \"2024-01-01\", \"train_end\": \"2024-06-30\", \"test_start\": \"2024-07-01\", \"test_end\": \"2024-12-31\", \"name\": \"Fold1_TEST\"},\n",
    "        {\"train_start\": \"2024-01-01\", \"train_end\": \"2024-12-31\", \"test_start\": \"2025-01-01\", \"test_end\": \"2025-06-30\", \"name\": \"Fold2_TEST\"},\n",
    "    ]\n",
    "else:\n",
    "    # ‚úÖ MODE PRODUCTION : 7 folds complets\n",
    "    WF_FOLDS = [\n",
    "        {\"train_start\": \"2020-01-01\", \"train_end\": \"2021-12-31\", \"test_start\": \"2022-01-01\", \"test_end\": \"2022-06-30\", \"name\": \"Fold1_Bull2020-21‚ÜíBear2022\"},\n",
    "        {\"train_start\": \"2020-01-01\", \"train_end\": \"2022-06-30\", \"test_start\": \"2022-07-01\", \"test_end\": \"2022-12-31\", \"name\": \"Fold2_Bull+Bear‚ÜíBear\"},\n",
    "        {\"train_start\": \"2020-01-01\", \"train_end\": \"2022-12-31\", \"test_start\": \"2023-01-01\", \"test_end\": \"2023-06-30\", \"name\": \"Fold3_Full‚ÜíRecovery\"},\n",
    "        {\"train_start\": \"2020-01-01\", \"train_end\": \"2023-06-30\", \"test_start\": \"2023-07-01\", \"test_end\": \"2023-12-31\", \"name\": \"Fold4_Recovery‚ÜíBull2023\"},\n",
    "        {\"train_start\": \"2020-01-01\", \"train_end\": \"2023-12-31\", \"test_start\": \"2024-01-01\", \"test_end\": \"2024-06-30\", \"name\": \"Fold5_Full‚ÜíBull2024-H1\"},\n",
    "        {\"train_start\": \"2020-01-01\", \"train_end\": \"2024-06-30\", \"test_start\": \"2024-07-01\", \"test_end\": \"2024-12-31\", \"name\": \"Fold6_2020-24-H1‚ÜíBull2024-H2\"},\n",
    "        {\"train_start\": \"2020-01-01\", \"train_end\": \"2024-12-31\", \"test_start\": \"2025-01-01\", \"test_end\": \"2025-06-30\", \"name\": \"Fold7_2020-24‚ÜíBull2025-H1\"},\n",
    "    ]\n",
    "\n",
    "# √âchantillon stratifi√© de paires repr√©sentatives\n",
    "if TEST_MODE:\n",
    "    # üß™ MODE TEST : 4 paires (1 par profil)\n",
    "    PAIRS = [\n",
    "        \"BTC/USDT:USDT\",   # Major\n",
    "        \"SOL/USDT:USDT\",   # Mid-cap\n",
    "        \"DOGE/USDT:USDT\",  # Volatile\n",
    "        \"TRX/USDT:USDT\",   # Low performer\n",
    "    ]\n",
    "else:\n",
    "    # ‚úÖ MODE PRODUCTION : 8 paires compl√®tes\n",
    "    PAIRS = [\n",
    "        \"BTC/USDT:USDT\",   # Major\n",
    "        \"ETH/USDT:USDT\",   # Major\n",
    "        \"SOL/USDT:USDT\",   # Mid-cap\n",
    "        \"AVAX/USDT:USDT\",  # Mid-cap\n",
    "        \"ADA/USDT:USDT\",   # Mid-cap\n",
    "        \"DOGE/USDT:USDT\",  # Volatile\n",
    "        \"SUSHI/USDT:USDT\", # Volatile (meilleur performer historique)\n",
    "        \"TRX/USDT:USDT\",   # Low performer\n",
    "    ]\n",
    "\n",
    "# Classification par profil\n",
    "PAIR_CLASSES = {\n",
    "    \"BTC/USDT:USDT\": \"major\",\n",
    "    \"ETH/USDT:USDT\": \"major\",\n",
    "    \"SOL/USDT:USDT\": \"mid-cap\",\n",
    "    \"AVAX/USDT:USDT\": \"mid-cap\",\n",
    "    \"ADA/USDT:USDT\": \"mid-cap\",\n",
    "    \"DOGE/USDT:USDT\": \"volatile\",\n",
    "    \"SUSHI/USDT:USDT\": \"volatile\",\n",
    "    \"TRX/USDT:USDT\": \"low\",\n",
    "}\n",
    "\n",
    "# Param√®tres de backtest communs\n",
    "BACKTEST_PARAMS = {\n",
    "    \"initial_wallet\": INITIAL_WALLET,\n",
    "    \"leverage\": BACKTEST_LEVERAGE,\n",
    "    \"maker_fee\": 0.0002,\n",
    "    \"taker_fee\": 0.0006,\n",
    "    \"reinvest\": True,\n",
    "    \"liquidation\": True,\n",
    "    \"risk_mode\": \"scaling\",\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Configuration charg√©e\")\n",
    "if TEST_MODE:\n",
    "    print(f\"   üß™ MODE TEST RAPIDE\")\n",
    "    print(f\"   Folds: {len(WF_FOLDS)} (au lieu de 7)\")\n",
    "    print(f\"   Paires: {len(PAIRS)} (au lieu de 8)\")\n",
    "else:\n",
    "    print(f\"   P√©riode: {PERIODS['train_full']['start']} ‚Üí {PERIODS['holdout']['end']} (BULL 2020-21, BEAR 2022, RECOVERY 2023, BULL 2024)\")\n",
    "    print(f\"   Paires: {len(PAIRS)} (√©chantillon stratifi√©)\")\n",
    "print(f\"   - Majors: {sum(1 for p in PAIRS if PAIR_CLASSES.get(p) == 'major')}\")\n",
    "print(f\"   - Mid-caps: {sum(1 for p in PAIRS if PAIR_CLASSES.get(p) == 'mid-cap')}\")\n",
    "print(f\"   - Volatiles: {sum(1 for p in PAIRS if PAIR_CLASSES.get(p) == 'volatile')}\")\n",
    "print(f\"   - Low performers: {sum(1 for p in PAIRS if PAIR_CLASSES.get(p) == 'low')}\")\n",
    "print(f\"   Walk-Forward Folds: {len(WF_FOLDS)}\")\n",
    "if not TEST_MODE:\n",
    "    print(f\"   Hold-out: {PERIODS['holdout']['start']} ‚Üí {PERIODS['holdout']['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e\n",
      "   P√©riode: 2020-01-01 ‚Üí 2025-10-03 (BULL 2020-21, BEAR 2022, RECOVERY 2023, BULL 2024)\n",
      "   Paires: 8 (√©chantillon stratifi√©)\n",
      "   - Majors: 2\n",
      "   - Mid-caps: 3\n",
      "   - Volatiles: 2\n",
      "   - Low performers: 1\n",
      "   Walk-Forward Folds: 7\n",
      "   Hold-out: 2025-07-01 ‚Üí 2025-10-03\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# CONFIGURATION GLOBALE\n",
    "# ======================\n",
    "\n",
    "BACKTEST_LEVERAGE = 10\n",
    "INITIAL_WALLET = 1000\n",
    "EXCHANGE = \"binance\"\n",
    "\n",
    "# P√©riodes (Expanding Window)\n",
    "# Couvre tous les cycles: BULL 2020-2021, BEAR 2022, RECOVERY 2023, BULL 2024, BULL 2025\n",
    "PERIODS = {\n",
    "    \"train_full\": {\"start\": \"2020-01-01\", \"end\": \"2025-06-30\"},  # Optimisation (toute la p√©riode sauf 3 mois)\n",
    "    \"holdout\": {\"start\": \"2025-07-01\", \"end\": \"2025-10-03\"},     # Validation finale (3 derniers mois)\n",
    "}\n",
    "\n",
    "# Walk-Forward Folds (Expanding Window)\n",
    "WF_FOLDS = [\n",
    "    {\"train_start\": \"2020-01-01\", \"train_end\": \"2021-12-31\", \"test_start\": \"2022-01-01\", \"test_end\": \"2022-06-30\", \"name\": \"Fold1_Bull2020-21‚ÜíBear2022\"},\n",
    "    {\"train_start\": \"2020-01-01\", \"train_end\": \"2022-06-30\", \"test_start\": \"2022-07-01\", \"test_end\": \"2022-12-31\", \"name\": \"Fold2_Bull+Bear‚ÜíBear\"},\n",
    "    {\"train_start\": \"2020-01-01\", \"train_end\": \"2022-12-31\", \"test_start\": \"2023-01-01\", \"test_end\": \"2023-06-30\", \"name\": \"Fold3_Full‚ÜíRecovery\"},\n",
    "    {\"train_start\": \"2020-01-01\", \"train_end\": \"2023-06-30\", \"test_start\": \"2023-07-01\", \"test_end\": \"2023-12-31\", \"name\": \"Fold4_Recovery‚ÜíBull2023\"},\n",
    "    {\"train_start\": \"2020-01-01\", \"train_end\": \"2023-12-31\", \"test_start\": \"2024-01-01\", \"test_end\": \"2024-06-30\", \"name\": \"Fold5_Full‚ÜíBull2024-H1\"},\n",
    "    {\"train_start\": \"2020-01-01\", \"train_end\": \"2024-06-30\", \"test_start\": \"2024-07-01\", \"test_end\": \"2024-12-31\", \"name\": \"Fold6_2020-24-H1‚ÜíBull2024-H2\"},\n",
    "    {\"train_start\": \"2020-01-01\", \"train_end\": \"2024-12-31\", \"test_start\": \"2025-01-01\", \"test_end\": \"2025-06-30\", \"name\": \"Fold7_2020-24‚ÜíBull2025-H1\"},\n",
    "]\n",
    "\n",
    "# √âchantillon stratifi√© de 8 paires repr√©sentatives\n",
    "# (couvre majors, mid-caps, volatiles, low performers)\n",
    "PAIRS = [\n",
    "    \"BTC/USDT:USDT\",   # Major\n",
    "    \"ETH/USDT:USDT\",   # Major\n",
    "    \"SOL/USDT:USDT\",   # Mid-cap\n",
    "    \"AVAX/USDT:USDT\",  # Mid-cap\n",
    "    \"ADA/USDT:USDT\",   # Mid-cap\n",
    "    \"DOGE/USDT:USDT\",  # Volatile\n",
    "    \"SUSHI/USDT:USDT\", # Volatile (meilleur performer historique)\n",
    "    \"TRX/USDT:USDT\",   # Low performer\n",
    "]\n",
    "\n",
    "# Classification par profil\n",
    "PAIR_CLASSES = {\n",
    "    \"BTC/USDT:USDT\": \"major\",\n",
    "    \"ETH/USDT:USDT\": \"major\",\n",
    "    \"SOL/USDT:USDT\": \"mid-cap\",\n",
    "    \"AVAX/USDT:USDT\": \"mid-cap\",\n",
    "    \"ADA/USDT:USDT\": \"mid-cap\",\n",
    "    \"DOGE/USDT:USDT\": \"volatile\",\n",
    "    \"SUSHI/USDT:USDT\": \"volatile\",\n",
    "    \"TRX/USDT:USDT\": \"low\",\n",
    "}\n",
    "\n",
    "# Param√®tres de backtest communs\n",
    "BACKTEST_PARAMS = {\n",
    "    \"initial_wallet\": INITIAL_WALLET,\n",
    "    \"leverage\": BACKTEST_LEVERAGE,\n",
    "    \"maker_fee\": 0.0002,\n",
    "    \"taker_fee\": 0.0006,\n",
    "    \"reinvest\": True,\n",
    "    \"liquidation\": True,\n",
    "    \"risk_mode\": \"scaling\",\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Configuration charg√©e\")\n",
    "print(f\"   P√©riode: {PERIODS['train_full']['start']} ‚Üí {PERIODS['holdout']['end']} (BULL 2020-21, BEAR 2022, RECOVERY 2023, BULL 2024)\")\n",
    "print(f\"   Paires: {len(PAIRS)} (√©chantillon stratifi√©)\")\n",
    "print(f\"   - Majors: {sum(1 for c in PAIR_CLASSES.values() if c == 'major')}\")\n",
    "print(f\"   - Mid-caps: {sum(1 for c in PAIR_CLASSES.values() if c == 'mid-cap')}\")\n",
    "print(f\"   - Volatiles: {sum(1 for c in PAIR_CLASSES.values() if c == 'volatile')}\")\n",
    "print(f\"   - Low performers: {sum(1 for c in PAIR_CLASSES.values() if c == 'low')}\")\n",
    "print(f\"   Walk-Forward Folds: {len(WF_FOLDS)}\")\n",
    "print(f\"   Hold-out: {PERIODS['holdout']['start']} ‚Üí {PERIODS['holdout']['end']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Profiles map charg√© : 30 pairs\n",
      "Profil major      :  12 configs √ó 2 pairs\n",
      "Profil mid-cap    :  27 configs √ó 3 pairs\n",
      "Profil volatile   :  12 configs √ó 2 pairs\n",
      "Profil low        :   2 configs √ó 1 pairs\n",
      "\n",
      "‚úÖ Total configs profils : 53\n",
      "   Total backtests : 371 (Fixed + Adaptive)\n"
     ]
    }
   ],
   "source": [
    "# === CELL-3b : GRILLES PAR PROFIL (MULTIPLICATEURS + NB ENV AUTO) ===\n",
    "\n",
    "# Config globale de r√©f√©rence (issue de l'optimisation √âtape 1)\n",
    "BASE_CONFIG = {\n",
    "    'ma_base_window': 5,           # Meilleure MA de l'optimisation globale\n",
    "    'envelopes_3': [0.07, 0.1, 0.15],     # Base pour 3 envelopes\n",
    "    'envelopes_4': [0.07, 0.1, 0.15, 0.20],  # Base pour 4 envelopes\n",
    "    'size': 0.12,                  # Meilleur size de l'optimisation globale\n",
    "    'stop_loss': 0.25\n",
    "}\n",
    "\n",
    "# Multiplicateurs par profil (au lieu de valeurs absolues)\n",
    "# Objectif : R√©duire l'espace de recherche tout en adaptant aux volatilit√©s\n",
    "PROFILE_MULTIPLIERS = {\n",
    "    \"major\": {\n",
    "        \"mult\": [0.8, 0.9, 1.0],        # BTC/ETH - envelopes plus tight\n",
    "        \"ma\": [5, 7],                    # MA standard\n",
    "        \"size\": [0.10, 0.12]             # Size conservateur\n",
    "    },\n",
    "    \"mid-cap\": {\n",
    "        \"mult\": [1.0, 1.1, 1.2],        # SOL/AVAX - envelopes standard+\n",
    "        \"ma\": [5, 7, 10],                # MA variable\n",
    "        \"size\": [0.10, 0.12, 0.14]       # Size variable\n",
    "    },\n",
    "    \"volatile\": {\n",
    "        \"mult\": [1.2, 1.3, 1.4],        # DOGE/SUSHI - envelopes larges\n",
    "        \"ma\": [5, 7],                    # MA court pour r√©activit√©\n",
    "        \"size\": [0.12, 0.14]             # Size plus agressif\n",
    "    },\n",
    "    \"low\": {\n",
    "        \"mult\": [1.0],                  # TRX - envelopes standard\n",
    "        \"ma\": [7, 10],                   # MA long (peu de signaux)\n",
    "        \"size\": [0.10]                   # Size conservateur\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fonction pour g√©n√©rer grilles par profil\n",
    "def generate_profile_grid(profile, pairs_in_profile):\n",
    "    \"\"\"\n",
    "    G√©n√®re la grille de configs pour un profil donn√©\n",
    "\n",
    "    Args:\n",
    "        profile: Nom du profil (major, mid-cap, volatile, low)\n",
    "        pairs_in_profile: Liste des pairs dans ce profil\n",
    "\n",
    "    Returns:\n",
    "        List de dicts avec configs √† tester\n",
    "    \"\"\"\n",
    "    configs = []\n",
    "\n",
    "    multipliers = PROFILE_MULTIPLIERS[profile][\"mult\"]\n",
    "    ma_windows = PROFILE_MULTIPLIERS[profile][\"ma\"]\n",
    "    sizes = PROFILE_MULTIPLIERS[profile][\"size\"]\n",
    "\n",
    "    for mult in multipliers:\n",
    "        for ma in ma_windows:\n",
    "            for size in sizes:\n",
    "                # G√©n√©rer config pour chaque pair du profil\n",
    "                pair_configs = {}\n",
    "\n",
    "                for pair in pairs_in_profile:\n",
    "                    # D√©terminer nb envelopes depuis mapping\n",
    "                    if df_envelope_mapping is not None and pair in df_envelope_mapping.index:\n",
    "                        n_env = df_envelope_mapping.loc[pair, 'n_envelopes']\n",
    "                    else:\n",
    "                        # Fallback : 3 env par d√©faut\n",
    "                        n_env = 3\n",
    "\n",
    "                    # S√©lectionner base selon nb envelopes\n",
    "                    base_env = BASE_CONFIG[f'envelopes_{n_env}']\n",
    "\n",
    "                    # Appliquer multiplicateur\n",
    "                    envelopes = [round(e * mult, 3) for e in base_env]\n",
    "\n",
    "                    pair_configs[pair] = {\n",
    "                        'ma_base_window': ma,\n",
    "                        'envelopes': envelopes,\n",
    "                        'size': size / 10  # Ajust√© pour leverage 10x (comme multi_envelope.ipynb)\n",
    "                    }\n",
    "\n",
    "                configs.append({\n",
    "                    'profile': profile,\n",
    "                    'mult': mult,\n",
    "                    'ma': ma,\n",
    "                    'size': size,\n",
    "                    'stop_loss': BASE_CONFIG['stop_loss'],\n",
    "                    'pair_configs': pair_configs,\n",
    "                    'adaptive': False  # Fixed params par d√©faut\n",
    "                })\n",
    "\n",
    "    return configs\n",
    "\n",
    "# Mapping pair -> profil (depuis profiles_map.csv ou manuel)\n",
    "PAIR_PROFILES = {\n",
    "    \"BTC/USDT:USDT\": \"major\",\n",
    "    \"ETH/USDT:USDT\": \"major\",\n",
    "    \"BNB/USDT:USDT\": \"mid-cap\",\n",
    "    \"SOL/USDT:USDT\": \"mid-cap\",\n",
    "    \"ADA/USDT:USDT\": \"mid-cap\",\n",
    "    \"AVAX/USDT:USDT\": \"mid-cap\",\n",
    "    \"AR/USDT:USDT\": \"mid-cap\",\n",
    "    \"ATOM/USDT:USDT\": \"mid-cap\",\n",
    "    \"DOGE/USDT:USDT\": \"volatile\",\n",
    "    \"SUSHI/USDT:USDT\": \"volatile\",\n",
    "    \"GALA/USDT:USDT\": \"volatile\",\n",
    "    \"TRX/USDT:USDT\": \"low\",\n",
    "}\n",
    "\n",
    "# Charger depuis profiles_map.csv si disponible\n",
    "if os.path.exists('profiles_map.csv'):\n",
    "    df_profiles_map = pd.read_csv('profiles_map.csv')\n",
    "    PAIR_PROFILES.update(dict(zip(df_profiles_map['pair'], df_profiles_map['profile'])))\n",
    "    print(f\"‚úÖ Profiles map charg√© : {len(PAIR_PROFILES)} pairs\")\n",
    "\n",
    "# G√©n√©rer toutes les grilles par profil\n",
    "PARAM_GRIDS_BY_PROFILE = {}\n",
    "\n",
    "for profile in PROFILE_MULTIPLIERS.keys():\n",
    "    # Filtrer pairs du profil\n",
    "    pairs_in_profile = [pair for pair in PAIRS if PAIR_PROFILES.get(pair) == profile]\n",
    "\n",
    "    if len(pairs_in_profile) > 0:\n",
    "        grid = generate_profile_grid(profile, pairs_in_profile)\n",
    "        PARAM_GRIDS_BY_PROFILE[profile] = grid\n",
    "\n",
    "        print(f\"Profil {profile:10s} : {len(grid):3d} configs √ó {len(pairs_in_profile)} pairs\")\n",
    "\n",
    "# Compter total configs\n",
    "total_configs = sum(len(grid) for grid in PARAM_GRIDS_BY_PROFILE.values())\n",
    "print(f\"\\n‚úÖ Total configs profils : {total_configs}\")\n",
    "\n",
    "if not TEST_MODE:\n",
    "    total_backtests = total_configs * len(WF_FOLDS) * 2  # Fixed + Adaptive\n",
    "else:\n",
    "    total_backtests = total_configs * len(WF_FOLDS)  # Fixed only en TEST_MODE\n",
    "\n",
    "print(f\"   Total backtests : {total_backtests} (Fixed + Adaptive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Chargement des donn√©es...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paires: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 37.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Donn√©es charg√©es\n",
      "   P√©riode: 2020-01-01 ‚Üí 2025-10-03 (BULL 2020-21, BEAR 2022, RECOVERY 2023, BULL 2024)\n",
      "   Paire la plus ancienne: BTC/USDT:USDT\n",
      "   Nombre de barres: 50458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Chargement des donn√©es\n",
    "exchange = ExchangeDataManager(\n",
    "    exchange_name=EXCHANGE,\n",
    "    path_download=\"../database/exchanges\"  # Pointe vers Backtest-Tools-V2/database/exchanges\n",
    ")\n",
    "\n",
    "# Charger TOUTES les donn√©es n√©cessaires (2020-2025 - couvre tous les cycles)\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2025-10-03\"\n",
    "\n",
    "df_list_full = {}\n",
    "print(\"üì• Chargement des donn√©es...\")\n",
    "for pair in tqdm(PAIRS, desc=\"Paires\"):\n",
    "    df = exchange.load_data(pair, \"1h\", start_date=start_date, end_date=end_date)\n",
    "    df_list_full[pair] = df\n",
    "\n",
    "# BTC pour d√©tection de r√©gime\n",
    "df_btc_full = exchange.load_data(\"BTC/USDT:USDT\", \"1h\", start_date=start_date, end_date=end_date)\n",
    "\n",
    "oldest_pair = min(df_list_full, key=lambda p: df_list_full[p].index.min())\n",
    "\n",
    "print(f\"\\n‚úÖ Donn√©es charg√©es\")\n",
    "print(f\"   P√©riode: {start_date} ‚Üí {end_date} (BULL 2020-21, BEAR 2022, RECOVERY 2023, BULL 2024)\")\n",
    "print(f\"   Paire la plus ancienne: {oldest_pair}\")\n",
    "print(f\"   Nombre de barres: {len(df_list_full[oldest_pair])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Comparaison manuelle de configurations pr√©-d√©finies\n",
    "\n",
    "Teste 5 configurations fixes pour comprendre l'impact des param√®tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã 5 configurations manuelles d√©finies\n",
      "   - Conservative: MA=10, Env=[0.05, 0.08, 0.12], Size=0.06\n",
      "   - Standard (Live actuel): MA=7, Env=[0.07, 0.1, 0.15], Size=0.1\n",
      "   - Aggressive: MA=5, Env=[0.09, 0.13, 0.18], Size=0.12\n",
      "   - Wide Envelopes: MA=7, Env=[0.1, 0.15, 0.2], Size=0.08\n",
      "   - Tight Envelopes: MA=7, Env=[0.05, 0.07, 0.1], Size=0.08\n"
     ]
    }
   ],
   "source": [
    "print(\"‚ö†Ô∏è  Section 2Ô∏è‚É£ Comparaison manuelle SKIPP√âE (nouveau format)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction run_single_backtest d√©finie\n"
     ]
    }
   ],
   "source": [
    "# Fonction helper pour run un backtest\n",
    "def run_single_backtest(df_list, oldest_pair, params_coin, stop_loss, params_adapter=None):\n",
    "    \"\"\"\n",
    "    Ex√©cute un backtest avec les param√®tres donn√©s.\n",
    "    \n",
    "    Returns:\n",
    "        dict: R√©sultat du backtest (trades, days, wallet, metrics)\n",
    "    \"\"\"\n",
    "    strategy = EnvelopeMulti_v2(\n",
    "        df_list=df_list,\n",
    "        oldest_pair=oldest_pair,\n",
    "        type=[\"long\", \"short\"],\n",
    "        params=params_coin\n",
    "    )\n",
    "    \n",
    "    strategy.populate_indicators()\n",
    "    strategy.populate_buy_sell()\n",
    "    \n",
    "    result = strategy.run_backtest(\n",
    "        **BACKTEST_PARAMS,\n",
    "        stop_loss=stop_loss,\n",
    "        params_adapter=params_adapter\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Fonction run_single_backtest d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions de parall√©lisation d√©finies\n",
      "   Gain attendu: ~4-5x avec votre i9-14900HX\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# PARALL√âLISATION MULTI-CORE\n",
    "# ======================\n",
    "\n",
    "def run_backtest_worker(args):\n",
    "    \"\"\"\n",
    "    Worker function pour ex√©cution parall√®le d'un backtest.\n",
    "    Doit √™tre une fonction top-level pour √™tre pickable par ProcessPoolExecutor.\n",
    "    \n",
    "    Args:\n",
    "        args: tuple (config_dict, df_list, params_coin, stop_loss, adapter_params, is_adaptive)\n",
    "    \n",
    "    Returns:\n",
    "        dict: R√©sultat du backtest avec m√©tadonn√©es\n",
    "    \"\"\"\n",
    "    config_dict, df_list_dict, params_coin, stop_loss, adapter_params, is_adaptive = args\n",
    "    \n",
    "    # Reconstituer les DataFrames depuis les dicts\n",
    "    df_list = {pair: pd.DataFrame(data) for pair, data in df_list_dict.items()}\n",
    "    \n",
    "    # Trouver oldest_pair\n",
    "    oldest_pair = min(df_list, key=lambda p: df_list[p].index.min())\n",
    "    \n",
    "    # Cr√©er l'adapter\n",
    "    if is_adaptive:\n",
    "        regime_series = pd.Series(adapter_params['regime_data'], \n",
    "                                  index=pd.DatetimeIndex(adapter_params['regime_index']))\n",
    "        adapter = RegimeBasedAdapter(\n",
    "            base_params=params_coin,\n",
    "            regime_series=regime_series,\n",
    "            regime_params=DEFAULT_PARAMS,\n",
    "            multipliers=adapter_params['multipliers'],\n",
    "            base_std=adapter_params['base_std']\n",
    "        )\n",
    "    else:\n",
    "        adapter = FixedParamsAdapter(params_coin)\n",
    "    \n",
    "    # Ex√©cuter backtest\n",
    "    strategy = EnvelopeMulti_v2(\n",
    "        df_list=df_list,\n",
    "        oldest_pair=oldest_pair,\n",
    "        type=[\"long\", \"short\"],\n",
    "        params=params_coin\n",
    "    )\n",
    "    \n",
    "    strategy.populate_indicators()\n",
    "    strategy.populate_buy_sell()\n",
    "    \n",
    "    result = strategy.run_backtest(\n",
    "        **BACKTEST_PARAMS,\n",
    "        stop_loss=stop_loss,\n",
    "        params_adapter=adapter\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'config': config_dict,\n",
    "        'wallet': result['days']['wallet'].iloc[-1] if len(result['days']) > 0 else INITIAL_WALLET,\n",
    "        'sharpe': result.get('sharpe_ratio', 0),\n",
    "        'n_trades': len(result['trades']),\n",
    "        'result': result  # Garder le r√©sultat complet\n",
    "    }\n",
    "\n",
    "\n",
    "def run_backtests_parallel(configs, df_list, regime_series=None, max_workers=None):\n",
    "    \"\"\"\n",
    "    Ex√©cute plusieurs backtests en parall√®le sur plusieurs cores CPU.\n",
    "    \n",
    "    Args:\n",
    "        configs: list de dicts avec les param√®tres de config\n",
    "        df_list: dict de DataFrames par paire\n",
    "        regime_series: Series des r√©gimes (si adaptive)\n",
    "        max_workers: nombre de workers (None = auto)\n",
    "    \n",
    "    Returns:\n",
    "        list: R√©sultats des backtests\n",
    "    \"\"\"\n",
    "    # Pr√©parer arguments pour chaque worker\n",
    "    tasks = []\n",
    "    \n",
    "    for config in configs:\n",
    "        # Convertir DataFrames en dicts pour serialization\n",
    "        df_list_dict = {pair: df.to_dict('list') for pair, df in df_list.items()}\n",
    "        \n",
    "        # Pr√©parer params_coin\n",
    "        params_coin = {}\n",
    "        for pair in df_list.keys():\n",
    "            params_coin[pair] = {\n",
    "                \"src\": \"close\",\n",
    "                \"ma_base_window\": config['ma_window'],\n",
    "                \"envelopes\": config['envelopes'],\n",
    "                \"size\": config['size'] / BACKTEST_LEVERAGE\n",
    "            }\n",
    "        \n",
    "        # Adapter params\n",
    "        if config['adaptive']:\n",
    "            adapter_params = {\n",
    "                'regime_data': regime_series.values.tolist(),\n",
    "                'regime_index': regime_series.index.tolist(),\n",
    "                'multipliers': {'envelope_std': True},\n",
    "                'base_std': 0.10\n",
    "            }\n",
    "        else:\n",
    "            adapter_params = None\n",
    "        \n",
    "        tasks.append((\n",
    "            config,\n",
    "            df_list_dict,\n",
    "            params_coin,\n",
    "            config['stop_loss'],\n",
    "            adapter_params,\n",
    "            config['adaptive']\n",
    "        ))\n",
    "    \n",
    "    # Ex√©cution parall√®le\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(run_backtest_worker, task): i for i, task in enumerate(tasks)}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Backtests parall√®les\"):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur backtest: {e}\")\n",
    "                results.append(None)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonctions de parall√©lisation d√©finies\")\n",
    "print(f\"   Gain attendu: ~4-5x avec votre i9-14900HX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Distribution des r√©gimes (2020-2025):\n",
      "   BULL: 48.3%\n",
      "   BEAR: 39.1%\n",
      "   RECOVERY: 12.6%\n"
     ]
    }
   ],
   "source": [
    "# Calculer les r√©gimes sur TOUTE la p√©riode (pour comparaison manuelle seulement)\n",
    "# ‚ö†Ô∏è Pour Walk-Forward, on recalculera par fold\n",
    "regime_series_full = calculate_regime_series(df_btc_full, confirm_n=12)\n",
    "\n",
    "print(\"üìä Distribution des r√©gimes (2020-2025):\")\n",
    "regime_counts = regime_series_full.value_counts(normalize=True) * 100\n",
    "for regime, pct in regime_counts.items():\n",
    "    print(f\"   {regime.name}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Section comparaison manuelle SKIPP√âE (nouveau format grilles)\n",
      "   Passer directement √† Walk-Forward Optimization\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Section 2Ô∏è‚É£ : Comparaison Manuelle SKIP\n",
    "# ========================================\n",
    "print(\"‚ö†Ô∏è  Section comparaison manuelle SKIPP√âE (nouveau format grilles)\")\n",
    "print(\"   Passer directement √† Walk-Forward Optimization\\n\")\n",
    "\n",
    "# Si tu veux vraiment tester une config manuellement :\n",
    "# 1. Choisis un profil\n",
    "# 2. Prends la premi√®re config de PARAM_GRIDS_BY_PROFILE[profile]\n",
    "# 3. Lance run_single_backtest avec cette config\n",
    "\n",
    "# Exemple (optionnel) :\n",
    "if False:  # Mettre True pour activer\n",
    "    test_profile = \"major\"\n",
    "    test_config = PARAM_GRIDS_BY_PROFILE[test_profile][0]\n",
    "    \n",
    "    pairs_in_profile = [pair for pair in PAIRS if PAIR_PROFILES.get(pair) == test_profile]\n",
    "    df_list_profile = {pair: df_list_full[pair] for pair in pairs_in_profile if pair in df_list_full}\n",
    "    \n",
    "    params_coin = test_config['pair_configs']\n",
    "    \n",
    "    adapter_fixed = FixedParamsAdapter(params_coin)\n",
    "    result = run_single_backtest(\n",
    "        df_list_profile,\n",
    "        oldest_pair,\n",
    "        params_coin,\n",
    "        test_config['stop_loss'],\n",
    "        adapter_fixed\n",
    "    )\n",
    "    \n",
    "    print(f\"Test config {test_profile}: Sharpe={result.get('sharpe_ratio', 0):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîç COMPARAISON DES BACKTESTS\n",
      "================================================================================\n",
      "            Strategy  Final Wallet  Total Perf (%)  Sharpe Ratio  Max DD (%)  Win Rate (%)  N Trades  Avg PnL (%)  Max Win (%)  Max Loss (%)  Total Fees  Avg Exposition  Avg Long Expo  Avg Short Expo  Avg Duration (h)\n",
      "Conservative (Fixed)   1388.577859       38.857786       2.03501   -2.213967     72.709163       502      1.32378    11.024478     -9.753471    11.77701        2.334245       1.413402        0.920843          3.782869\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ RECOMMANDATION: Conservative (Fixed)\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Afficher les r√©sultats\n",
    "comparator_manual.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Comparaison sauvegard√©e: results_manual_20251005_105352.csv\n",
      "üíæ R√©sultats sauvegard√©s: results_manual_20251005_105352.csv\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les r√©sultats manuels\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "comparator_manual.save_comparison(f\"results_manual_{timestamp}.csv\")\n",
    "print(f\"üíæ R√©sultats sauvegard√©s: results_manual_{timestamp}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Grid Search (INTERM√âDIAIRE - optimisation globale)\n",
      "   Combinaisons: 18\n",
      "   Walk-Forward Folds: 7\n",
      "   Total backtests: 252 (fixed + adaptive)\n",
      "   Temps estim√©: ~13 min avec multi-core\n",
      "   P√©riode: 2020-2025 (couvre BULL 2020-21, BEAR 2022, RECOVERY 2023, BULL 2024-25)\n",
      "\n",
      "üí° Approche incr√©mentale:\n",
      "   √âtape 1 (actuelle): Grid interm√©diaire global (18 configs)\n",
      "   √âtape 2 (si besoin): Optimisation par profil (4 grids s√©par√©s)\n"
     ]
    }
   ],
   "source": [
    "# Grid de param√®tres (INTERM√âDIAIRE - optimisation globale)\n",
    "# √âtape 1: Valider avec grid √©largi avant d'impl√©menter optimisation par profil\n",
    "PARAM_GRID = {\n",
    "    \"ma_base_window\": [5, 7, 10],           # 3 valeurs (r√©activit√©)\n",
    "    \"envelope_sets\": [\n",
    "        [0.07, 0.10, 0.15],                 # Standard (actuel live)\n",
    "        [0.10, 0.15, 0.20],                 # Wide (pour volatiles)\n",
    "    ],                                       # 2 sets\n",
    "    \"size\": [0.08, 0.10, 0.12],             # 3 valeurs (risque)\n",
    "    \"stop_loss\": [0.25],                    # 1 valeur (garder simple)\n",
    "}\n",
    "\n",
    "# G√©n√©rer toutes les combinaisons\n",
    "grid_combinations = list(product(\n",
    "    PARAM_GRID[\"ma_base_window\"],\n",
    "    PARAM_GRID[\"envelope_sets\"],\n",
    "    PARAM_GRID[\"size\"],\n",
    "    PARAM_GRID[\"stop_loss\"]\n",
    "))\n",
    "\n",
    "print(f\"üîç Grid Search (INTERM√âDIAIRE - optimisation globale)\")\n",
    "print(f\"   Combinaisons: {len(grid_combinations)}\")\n",
    "print(f\"   Walk-Forward Folds: {len(WF_FOLDS)}\")\n",
    "print(f\"   Total backtests: {len(grid_combinations) * len(WF_FOLDS) * 2} (fixed + adaptive)\")\n",
    "print(f\"   Temps estim√©: ~{len(grid_combinations) * len(WF_FOLDS) * 2 * 3 / 60:.0f} min avec multi-core\")\n",
    "print(f\"   P√©riode: 2020-2025 (couvre BULL 2020-21, BEAR 2022, RECOVERY 2023, BULL 2024-25)\")\n",
    "print(f\"\\nüí° Approche incr√©mentale:\")\n",
    "print(f\"   √âtape 1 (actuelle): Grid interm√©diaire global (18 configs)\")\n",
    "print(f\"   √âtape 2 (si besoin): Optimisation par profil (4 grids s√©par√©s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions de filtrage d√©finies\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour filtrer DataFrame par dates\n",
    "def filter_df_by_dates(df, start_date, end_date):\n",
    "    \"\"\"Filtre un DataFrame par dates.\"\"\"\n",
    "    mask = (df.index >= pd.Timestamp(start_date)) & (df.index <= pd.Timestamp(end_date))\n",
    "    return df[mask]\n",
    "\n",
    "def filter_df_list_by_dates(df_list, start_date, end_date):\n",
    "    \"\"\"Filtre un dict de DataFrames par dates.\"\"\"\n",
    "    return {pair: filter_df_by_dates(df, start_date, end_date) for pair, df in df_list.items()}\n",
    "\n",
    "print(\"‚úÖ Fonctions de filtrage d√©finies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction calculate_composite_score d√©finie\n"
     ]
    }
   ],
   "source": [
    "# Fonction de calcul du score composite anti-overfitting\n",
    "def calculate_composite_score(bt_result, train_sharpe=None):\n",
    "    \"\"\"\n",
    "    Calcule le score composite pour √©valuer une configuration.\n",
    "    \n",
    "    Args:\n",
    "        bt_result: R√©sultat du backtest\n",
    "        train_sharpe: Sharpe du train (pour consistency), None si on calcule train\n",
    "    \n",
    "    Returns:\n",
    "        float: Score composite (plus √©lev√© = meilleur)\n",
    "    \"\"\"\n",
    "    df_trades = bt_result['trades']\n",
    "    df_days = bt_result['days']\n",
    "    \n",
    "    # Calculer m√©triques de base\n",
    "    n_trades = len(df_trades)\n",
    "    \n",
    "    # Filtre: trop peu de trades = pas fiable\n",
    "    if n_trades < 10:\n",
    "        return -999  # Sera skip par early termination de toute fa√ßon\n",
    "    \n",
    "    # Poids r√©duit pour √©chantillons 10-30 trades\n",
    "    if n_trades < 30:\n",
    "        weight_penalty = n_trades / 30  # 0.33 √† 1.0\n",
    "    else:\n",
    "        weight_penalty = 1.0\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe = bt_result.get('sharpe_ratio', 0)\n",
    "    if pd.isna(sharpe) or np.isinf(sharpe):\n",
    "        sharpe = 0\n",
    "    \n",
    "    # Clip sharpe pour √©viter outliers\n",
    "    sharpe = np.clip(sharpe, -5, 10)\n",
    "    \n",
    "    # Max Drawdown\n",
    "    df_days_copy = df_days.copy()\n",
    "    df_days_copy['cummax'] = df_days_copy['wallet'].cummax()\n",
    "    df_days_copy['drawdown_pct'] = (df_days_copy['wallet'] - df_days_copy['cummax']) / df_days_copy['cummax']\n",
    "    max_dd = abs(df_days_copy['drawdown_pct'].min()) * 100\n",
    "    \n",
    "    # Calmar Ratio (return / max_dd)\n",
    "    final_wallet = df_days['wallet'].iloc[-1]\n",
    "    total_return = (final_wallet / INITIAL_WALLET - 1) * 100\n",
    "    calmar = total_return / max(max_dd, 1.0)  # √âviter division par 0\n",
    "    calmar = np.clip(calmar, -5, 10)  # Clip calmar\n",
    "    \n",
    "    # Win Rate\n",
    "    df_trades_copy = df_trades.copy()\n",
    "    if 'trade_result' not in df_trades_copy.columns:\n",
    "        df_trades_copy['trade_result'] = (\n",
    "            df_trades_copy[\"close_trade_size\"] -\n",
    "            df_trades_copy[\"open_trade_size\"] -\n",
    "            df_trades_copy[\"open_fee\"] -\n",
    "            df_trades_copy[\"close_fee\"]\n",
    "        )\n",
    "    win_rate = (df_trades_copy['trade_result'] > 0).mean()\n",
    "    \n",
    "    # Profit Factor\n",
    "    gross_profit = df_trades_copy[df_trades_copy['trade_result'] > 0]['trade_result'].sum()\n",
    "    gross_loss = abs(df_trades_copy[df_trades_copy['trade_result'] < 0]['trade_result'].sum())\n",
    "    profit_factor = gross_profit / max(gross_loss, 1.0) if gross_loss > 0 else gross_profit\n",
    "    profit_factor_normalized = np.clip(profit_factor / 2, 0, 1)  # Cap √† 1\n",
    "    \n",
    "    # Consistency (train vs test)\n",
    "    if train_sharpe is not None:\n",
    "        consistency = 1 - abs(train_sharpe - sharpe) / max(0.1, abs(train_sharpe))\n",
    "        consistency = np.clip(consistency, 0, 1)  # Clip √† [0,1]\n",
    "    else:\n",
    "        consistency = 0  # Pas de consistency pour train\n",
    "    \n",
    "    # DD factor\n",
    "    dd_factor = np.clip(1 - min(max_dd, 100) / 100, 0, 1)\n",
    "    \n",
    "    # Score composite\n",
    "    if train_sharpe is None:  # Train\n",
    "        score = (\n",
    "            sharpe * 0.35 +\n",
    "            calmar * 0.25 +\n",
    "            dd_factor * 0.20 +\n",
    "            win_rate * 0.10 +\n",
    "            profit_factor_normalized * 0.10\n",
    "        ) * weight_penalty\n",
    "    else:  # Test\n",
    "        score = (\n",
    "            sharpe * 0.30 +\n",
    "            consistency * 0.25 +\n",
    "            calmar * 0.20 +\n",
    "            dd_factor * 0.15 +\n",
    "            win_rate * 0.05 +\n",
    "            profit_factor_normalized * 0.05\n",
    "        ) * weight_penalty\n",
    "    \n",
    "    return score\n",
    "\n",
    "print(\"‚úÖ Fonction calculate_composite_score d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Cache indicateurs d√©sactiv√© (nouveau format grilles)\n"
     ]
    }
   ],
   "source": [
    "# Cache d√©sactiv√© temporairement (nouveau format de grilles)\n",
    "# Le cache sera r√©activ√© apr√®s adaptation √† PARAM_GRIDS_BY_PROFILE\n",
    "cache = None\n",
    "print(\"‚ö†Ô∏è  Cache indicateurs d√©sactiv√© (nouveau format grilles)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Cache indicateurs d√©sactiv√© (nouveau format grilles)\n",
      "\n",
      "üöÄ D√©marrage Walk-Forward Optimization PAR PROFIL (OPTIMIS√âE)...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üî¨ OPTIMISATION PROFIL: MAJOR\n",
      "================================================================================\n",
      "   Paires: BTC/USDT:USDT, ETH/USDT:USDT (2 paires)\n",
      "   Configs √† tester: 12\n",
      "   üß™ MODE TEST: Fixed only (skip Adaptive)\n",
      "   Total backtests: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MAJOR WFO:   0%|          | 0/84 [01:51<?, ?it/s]\n",
      "MAJOR WFO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [04:48<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ 84 r√©sultats enregistr√©s pour major\n",
      "\n",
      "================================================================================\n",
      "üî¨ OPTIMISATION PROFIL: MID-CAP\n",
      "================================================================================\n",
      "   Paires: SOL/USDT:USDT, AVAX/USDT:USDT, ADA/USDT:USDT (3 paires)\n",
      "   Configs √† tester: 27\n",
      "   üß™ MODE TEST: Fixed only (skip Adaptive)\n",
      "   Total backtests: 189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MID-CAP WFO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 189/189 [17:18<00:00,  5.50s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ 189 r√©sultats enregistr√©s pour mid-cap\n",
      "\n",
      "================================================================================\n",
      "üî¨ OPTIMISATION PROFIL: VOLATILE\n",
      "================================================================================\n",
      "   Paires: DOGE/USDT:USDT, SUSHI/USDT:USDT (2 paires)\n",
      "   Configs √† tester: 12\n",
      "   üß™ MODE TEST: Fixed only (skip Adaptive)\n",
      "   Total backtests: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VOLATILE WFO:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 54/84 [03:01<01:41,  3.37s/it]"
     ]
    }
   ],
   "source": [
    "# =================================================================\n",
    "# CELL-19 OPTIMIS√âE - Walk-Forward avec Palier 1 (√ó1.5-2.5 gain)\n",
    "# =================================================================\n",
    "# Optimisations:\n",
    "# 1. Cache des indicateurs (pr√©-calcul)\n",
    "# 2. Early termination (skip configs non-viables)\n",
    "# 3. Batching intelligent (r√©duction overhead)\n",
    "\n",
    "from indicator_cache import IndicatorCache, precompute_all_indicators\n",
    "\n",
    "# Initialiser le cache\n",
    "cache = IndicatorCache(cache_dir=\"./cache_indicators\")\n",
    "\n",
    "# Cache d√©sactiv√© temporairement (nouveau format de grilles incompatible)\n",
    "# precompute_all_indicators(df_list_full, PARAM_GRIDS_BY_PROFILE, PERIODS, cache)\n",
    "cache = None\n",
    "print(\"‚ö†Ô∏è  Cache indicateurs d√©sactiv√© (nouveau format grilles)\")\n",
    "\n",
    "# Walk-Forward Optimization PAR PROFIL (OPTIMIS√âE)\n",
    "wf_results_by_profile = {}\n",
    "\n",
    "print(\"\\nüöÄ D√©marrage Walk-Forward Optimization PAR PROFIL (OPTIMIS√âE)...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for profile in PARAM_GRIDS_BY_PROFILE.keys():\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"üî¨ OPTIMISATION PROFIL: {profile.upper()}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    # Filtrer les paires du profil\n",
    "    pairs_in_profile = [pair for pair in PAIRS if PAIR_PROFILES.get(pair) == profile]\n",
    "\n",
    "    if len(pairs_in_profile) == 0:\n",
    "        print(f\"‚ö†Ô∏è  Aucune paire dans le profil {profile}, skip\")\n",
    "        continue\n",
    "\n",
    "    print(f\"   Paires: {', '.join(pairs_in_profile)} ({len(pairs_in_profile)} paires)\")\n",
    "\n",
    "    # G√©n√©rer combinaisons pour ce profil\n",
    "    grid = PARAM_GRIDS_BY_PROFILE[profile]\n",
    "    # grid est maintenant une liste de configs (nouveau format)\n",
    "    grid_combinations_profile = grid  # Pas besoin de product(), les configs sont d√©j√† g√©n√©r√©es\n",
    "\n",
    "    print(f\"   Configs √† tester: {len(grid_combinations_profile)}\")\n",
    "\n",
    "    # Calculer iterations selon TEST_MODE\n",
    "    if TEST_MODE:\n",
    "        total_iterations = len(WF_FOLDS) * len(grid_combinations_profile)\n",
    "        print(f\"   üß™ MODE TEST: Fixed only (skip Adaptive)\")\n",
    "    else:\n",
    "        total_iterations = len(WF_FOLDS) * len(grid_combinations_profile) * 2\n",
    "\n",
    "    print(f\"   Total backtests: {total_iterations}\")\n",
    "\n",
    "    # Walk-Forward Loop avec early termination\n",
    "    wf_results = []\n",
    "    skipped_configs = 0\n",
    "    pbar = tqdm(total=total_iterations, desc=f\"{profile.upper()} WFO\")\n",
    "\n",
    "    for combo_idx, config in enumerate(grid_combinations_profile):\n",
    "        # Extraire params de la config\n",
    "        ma = config['ma']\n",
    "        size = config['size']\n",
    "        sl = config['stop_loss']\n",
    "        pair_configs = config['pair_configs']  # Nouveau : configs par pair\n",
    "\n",
    "        # Early termination: skip si config d√©j√† mauvaise sur premiers folds\n",
    "        should_skip = False\n",
    "        fold_count = 0\n",
    "\n",
    "        for fold in WF_FOLDS:\n",
    "            fold_name = fold[\"name\"]\n",
    "            fold_count += 1\n",
    "\n",
    "            # Filtrer donn√©es par p√©riode\n",
    "            df_list_train = filter_df_list_by_dates(df_list_full, fold['train_start'], fold['train_end'])\n",
    "            df_list_test = filter_df_list_by_dates(df_list_full, fold['test_start'], fold['test_end'])\n",
    "\n",
    "            df_btc_train = filter_df_by_dates(df_btc_full, fold['train_start'], fold['train_end'])\n",
    "            df_btc_test = filter_df_by_dates(df_btc_full, fold['test_start'], fold['test_end'])\n",
    "\n",
    "            # Filtrer par profil\n",
    "            df_list_train_profile = {p: df for p, df in df_list_train.items() if p in pairs_in_profile}\n",
    "            df_list_test_profile = {p: df for p, df in df_list_test.items() if p in pairs_in_profile}\n",
    "\n",
    "            # Calculer r√©gimes par fold\n",
    "            regime_train = calculate_regime_series(df_btc_train, confirm_n=12)\n",
    "            regime_test = calculate_regime_series(df_btc_test, confirm_n=12)\n",
    "\n",
    "            # Garde-fou : V√©rifier fold valide\n",
    "            if len(df_list_train_profile) == 0 or len(df_list_test_profile) == 0:\n",
    "                print(f\"      ‚ö†Ô∏è  {fold_name}: Donn√©es insuffisantes, skip fold\")\n",
    "                pbar.update(1 if TEST_MODE else 2)\n",
    "                continue\n",
    "\n",
    "            # Pr√©parer params_coin depuis pair_configs (d√©j√† dans le bon format)\n",
    "            params_coin = {}\n",
    "            for pair in pairs_in_profile:\n",
    "                if pair in pair_configs:\n",
    "                    params_coin[pair] = {\n",
    "                        \"src\": \"close\",\n",
    "                        **pair_configs[pair]  # Contient d√©j√† ma_base_window, envelopes, size\n",
    "                    }\n",
    "\n",
    "            # === TRAIN ===\n",
    "            adapter_fixed = FixedParamsAdapter(params_coin)\n",
    "            bt_train_fixed = run_single_backtest(\n",
    "                df_list_train_profile, min(df_list_train_profile, key=lambda p: df_list_train_profile[p].index.min()),\n",
    "                params_coin, sl, adapter_fixed\n",
    "            )\n",
    "            score_train_fixed = calculate_composite_score(bt_train_fixed)\n",
    "            sharpe_train_fixed = bt_train_fixed.get('sharpe_ratio', 0)\n",
    "\n",
    "            # === TEST ===\n",
    "            adapter_fixed_test = FixedParamsAdapter(params_coin)\n",
    "            bt_test_fixed = run_single_backtest(\n",
    "                df_list_test_profile, min(df_list_test_profile, key=lambda p: df_list_test_profile[p].index.min()),\n",
    "                params_coin, sl, adapter_fixed_test\n",
    "            )\n",
    "            score_test_fixed = calculate_composite_score(bt_test_fixed, sharpe_train_fixed)\n",
    "\n",
    "            # üöÄ EARLY TERMINATION : Skip si trop peu de trades ou DD √©lev√© sur les 2 premiers folds\n",
    "            if fold_count <= 2:  # √âvaluer sur les 2 premiers folds\n",
    "                n_trades = len(bt_test_fixed['trades'])\n",
    "\n",
    "                # Calculer max DD\n",
    "                df_days = bt_test_fixed['days']\n",
    "                if len(df_days) > 0:\n",
    "                    df_days_copy = df_days.copy()\n",
    "                    df_days_copy['cummax'] = df_days_copy['wallet'].cummax()\n",
    "                    df_days_copy['drawdown_pct'] = (df_days_copy['wallet'] - df_days_copy['cummax']) / df_days_copy['cummax']\n",
    "                    max_dd = abs(df_days_copy['drawdown_pct'].min()) * 100\n",
    "                else:\n",
    "                    max_dd = 0\n",
    "\n",
    "                # Conditions d'√©limination pr√©coce\n",
    "                if n_trades < 10:  # Trop peu de trades\n",
    "                    should_skip = True\n",
    "                    skip_reason = f\"<10 trades (fold {fold_count})\"\n",
    "                elif max_dd > 50:  # DD trop √©lev√©\n",
    "                    should_skip = True\n",
    "                    skip_reason = f\"DD>{max_dd:.1f}% (fold {fold_count})\"\n",
    "                elif score_test_fixed < -500:  # Score catastrophique\n",
    "                    should_skip = True\n",
    "                    skip_reason = f\"score<-500 (fold {fold_count})\"\n",
    "\n",
    "            # Stocker r√©sultats Fixed\n",
    "            wf_results.append({\n",
    "                \"profile\": profile,\n",
    "                \"fold\": fold_name,\n",
    "                \"combo_idx\": combo_idx,\n",
    "                \"ma_window\": ma,\n",
    "                \"envelopes\": str(list(pair_configs.values())[0]['envelopes']) if pair_configs else \"[]\",\n",
    "                \"size\": size,\n",
    "                \"stop_loss\": sl,\n",
    "                \"adaptive\": False,\n",
    "                \"train_wallet\": bt_train_fixed['wallet'],\n",
    "                \"train_sharpe\": sharpe_train_fixed,\n",
    "                \"train_score\": score_train_fixed,\n",
    "                \"train_trades\": len(bt_train_fixed['trades']),\n",
    "                \"test_wallet\": bt_test_fixed['wallet'],\n",
    "                \"test_sharpe\": bt_test_fixed.get('sharpe_ratio', 0),\n",
    "                \"test_score\": score_test_fixed,\n",
    "                \"test_trades\": len(bt_test_fixed['trades']),\n",
    "            })\n",
    "            pbar.update(1)\n",
    "\n",
    "            # === ADAPTIVE (skip en mode TEST) ===\n",
    "            if not TEST_MODE:\n",
    "                adapter_adaptive_train = RegimeBasedAdapter(\n",
    "                    base_params=params_coin,\n",
    "                    regime_series=regime_train,\n",
    "                    regime_params=DEFAULT_PARAMS,\n",
    "                    multipliers={'envelope_std': True},\n",
    "                    base_std=0.10\n",
    "                )\n",
    "                bt_train_adaptive = run_single_backtest(\n",
    "                    df_list_train_profile, min(df_list_train_profile, key=lambda p: df_list_train_profile[p].index.min()),\n",
    "                    params_coin, stop_loss, adapter_adaptive_train\n",
    "                )\n",
    "                score_train_adaptive = calculate_composite_score(bt_train_adaptive)\n",
    "                sharpe_train_adaptive = bt_train_adaptive.get('sharpe_ratio', 0)\n",
    "\n",
    "                adapter_adaptive_test = RegimeBasedAdapter(\n",
    "                    base_params=params_coin,\n",
    "                    regime_series=regime_test,\n",
    "                    regime_params=DEFAULT_PARAMS,\n",
    "                    multipliers={'envelope_std': True},\n",
    "                    base_std=0.10\n",
    "                )\n",
    "                bt_test_adaptive = run_single_backtest(\n",
    "                    df_list_test_profile, min(df_list_test_profile, key=lambda p: df_list_test_profile[p].index.min()),\n",
    "                    params_coin, stop_loss, adapter_adaptive_test\n",
    "                )\n",
    "                score_test_adaptive = calculate_composite_score(bt_test_adaptive, sharpe_train_adaptive)\n",
    "\n",
    "                wf_results.append({\n",
    "                    \"profile\": profile,\n",
    "                    \"fold\": fold_name,\n",
    "                    \"combo_idx\": combo_idx,\n",
    "                    \"ma_window\": ma,\n",
    "                    \"envelopes\": str(list(pair_configs.values())[0]['envelopes']) if pair_configs else \"[]\",\n",
    "                    \"size\": size,\n",
    "                    \"stop_loss\": stop_loss,\n",
    "                    \"adaptive\": True,\n",
    "                    \"train_wallet\": bt_train_adaptive['wallet'],\n",
    "                    \"train_sharpe\": sharpe_train_adaptive,\n",
    "                    \"train_score\": score_train_adaptive,\n",
    "                    \"train_trades\": len(bt_train_adaptive['trades']),\n",
    "                    \"test_wallet\": bt_test_adaptive['wallet'],\n",
    "                    \"test_sharpe\": bt_test_adaptive.get('sharpe_ratio', 0),\n",
    "                    \"test_score\": score_test_adaptive,\n",
    "                    \"test_trades\": len(bt_test_adaptive['trades']),\n",
    "                })\n",
    "                pbar.update(1)\n",
    "\n",
    "            # Si early termination d√©tect√©e, skip les folds restants\n",
    "            if should_skip:\n",
    "                remaining_folds = len(WF_FOLDS) - fold_count\n",
    "                pbar.update(remaining_folds * (1 if TEST_MODE else 2))\n",
    "                skipped_configs += 1\n",
    "                print(f\"      ‚è≠Ô∏è  Config#{combo_idx+1} skipped: {skip_reason}\")\n",
    "                break  # Sort de la boucle des folds\n",
    "\n",
    "    pbar.close()\n",
    "    wf_results_by_profile[profile] = pd.DataFrame(wf_results)\n",
    "    print(f\"   ‚úÖ {len(wf_results)} r√©sultats enregistr√©s pour {profile}\")\n",
    "    if skipped_configs > 0:\n",
    "        print(f\"   ‚è≠Ô∏è  {skipped_configs} configs skipped (early termination)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Walk-Forward Optimization PAR PROFIL termin√©e (OPTIMIS√âE)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les r√©sultats de tous les profils\n",
    "df_wf_all_profiles = pd.concat(list(wf_results_by_profile.values()), ignore_index=True)\n",
    "\n",
    "print(\"‚úÖ R√©sultats combin√©s de tous les profils\")\n",
    "print(f\"   Total r√©sultats: {len(df_wf_all_profiles)}\")\n",
    "print(f\"   Profils: {df_wf_all_profiles['profile'].unique().tolist()}\")\n",
    "\n",
    "# Meilleure config PAR PROFIL\n",
    "best_configs_by_profile = {}\n",
    "\n",
    "# Garde-fou #5 : Filtre trades minimum par profil\n",
    "MIN_TRADES_PER_PROFILE = 50\n",
    "\n",
    "# Pas de hard cutoff MIN_TRADES - utiliser syst√®me de poids √† la place\n",
    "for profile in PARAM_GRIDS_BY_PROFILE.keys():\n",
    "    df_profile = df_wf_all_profiles[df_wf_all_profiles['profile'] == profile]\n",
    "    \n",
    "    if len(df_profile) == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Profil {profile}: Aucun r√©sultat (profil skip)\")\n",
    "        continue\n",
    "\n",
    "    # Agr√©ger par config\n",
    "    df_profile_avg = df_profile.groupby(['ma_window', 'envelopes', 'size', 'stop_loss', 'adaptive']).agg({\n",
    "        'train_score': 'mean',\n",
    "        'test_score': 'mean',\n",
    "        'train_sharpe': 'mean',\n",
    "        'test_sharpe': 'mean',\n",
    "        'train_trades': 'sum',\n",
    "        'test_trades': 'sum',\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculer consistency\n",
    "    df_profile_avg['consistency'] = 1 - abs(df_profile_avg['train_sharpe'] - df_profile_avg['test_sharpe']) / df_profile_avg['train_sharpe'].abs().clip(lower=0.1)\n",
    "    df_profile_avg['consistency'] = df_profile_avg['consistency'].clip(lower=0)\n",
    "    \n",
    "    # Ajouter poids si pas pr√©sent (configs avec peu de trades ont d√©j√† weight r√©duit dans scoring)\n",
    "    if 'weight' not in df_profile_avg.columns:\n",
    "        # Calculer poids bas√© sur nombre de trades\n",
    "        df_profile_avg['weight'] = df_profile_avg['test_trades'].apply(\n",
    "            lambda x: 1.0 if x >= 50 else (0.25 if x >= 30 else (x / 30 if x >= 10 else 0.1))\n",
    "        )\n",
    "    \n",
    "    # Score pond√©r√©\n",
    "    df_profile_avg['weighted_score'] = df_profile_avg['test_score'] * df_profile_avg['weight']\n",
    "    \n",
    "    # Trier par score pond√©r√© (pas de filtrage dur)\n",
    "    df_profile_avg = df_profile_avg.sort_values('weighted_score', ascending=False)\n",
    "    \n",
    "    # Prendre le meilleur (pas de MIN_TRADES cutoff)\n",
    "    if len(df_profile_avg) > 0:\n",
    "        best_configs_by_profile[profile] = df_profile_avg.iloc[0]\n",
    "        \n",
    "        # Warning si peu de trades\n",
    "        n_trades = df_profile_avg.iloc[0]['test_trades']\n",
    "        weight = df_profile_avg.iloc[0]['weight']\n",
    "        if n_trades < 50:\n",
    "            print(f\"\\n‚ö†Ô∏è  Profil {profile}: {n_trades} trades (weight={weight:.2f})\")\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ Profil {profile}: {n_trades} trades\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Profil {profile}: Aucun r√©sultat\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"üèÜ MEILLEURES CONFIGURATIONS PAR PROFIL\")\n",
    "print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "for profile, best_cfg in best_configs_by_profile.items():\n",
    "    print(f\"{profile.upper()}:\")\n",
    "    print(f\"   MA: {int(best_cfg['ma_window'])}, Env: {best_cfg['envelopes']}, Size: {best_cfg['size']:.2f}, SL: {best_cfg['stop_loss']}\")\n",
    "    print(f\"   Adaptive: {best_cfg['adaptive']}\")\n",
    "    print(f\"   Train Sharpe: {best_cfg['train_sharpe']:.2f}, Test Sharpe: {best_cfg['test_sharpe']:.2f}\")\n",
    "    print(f\"   Test Score: {best_cfg['test_score']:.3f}, Consistency: {best_cfg['consistency']:.2f}\")\n",
    "    print(f\"   Trades: {int(best_cfg['test_trades'])}, Weight: {best_cfg.get('weight', 1.0):.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# GATE : Profil vs Global\n",
    "# ======================\n",
    "\n",
    "# Charger r√©sultats globaux (√âtape 1)\n",
    "try:\n",
    "    df_wf_global = pd.read_csv('wf_results_summary_20251004_235003.csv')  # R√©sultat √âtape 1\n",
    "    \n",
    "    # Score global moyen (meilleur)\n",
    "    best_global_score = df_wf_global['test_score'].max()\n",
    "    best_global_sharpe = df_wf_global.loc[df_wf_global['test_score'].idxmax(), 'test_sharpe']\n",
    "    best_global_config = df_wf_global.loc[df_wf_global['test_score'].idxmax()]\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"üìä GATE : Optimisation Profil vs Optimisation Globale\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    print(\"üîµ OPTIMISATION GLOBALE (√âtape 1)\")\n",
    "    print(f\"   MA: {best_global_config['ma_window']}, Env: {best_global_config['envelopes']}, Size: {best_global_config['size']}\")\n",
    "    print(f\"   Test Score: {best_global_score:.3f}\")\n",
    "    print(f\"   Test Sharpe: {best_global_sharpe:.2f}\\n\")\n",
    "    \n",
    "    # Score profil moyen (moyenne pond√©r√©e par nombre de paires)\n",
    "    profile_scores = []\n",
    "    for profile, best_cfg in best_configs_by_profile.items():\n",
    "        # Compter paires dans √©chantillon\n",
    "        n_pairs = len([p for p in PAIRS if PAIR_PROFILES.get(p) == profile])\n",
    "        profile_scores.append({\n",
    "            'profile': profile,\n",
    "            'score': best_cfg['test_score'],\n",
    "            'sharpe': best_cfg['test_sharpe'],\n",
    "            'weight': n_pairs\n",
    "        })\n",
    "    \n",
    "    df_profile_scores = pd.DataFrame(profile_scores)\n",
    "    weighted_avg_score = (df_profile_scores['score'] * df_profile_scores['weight']).sum() / df_profile_scores['weight'].sum()\n",
    "    weighted_avg_sharpe = (df_profile_scores['sharpe'] * df_profile_scores['weight']).sum() / df_profile_scores['weight'].sum()\n",
    "    \n",
    "    print(\"üü¢ OPTIMISATION PAR PROFIL (√âtape 2)\")\n",
    "    print(f\"   Weighted Avg Score: {weighted_avg_score:.3f}\")\n",
    "    print(f\"   Weighted Avg Sharpe: {weighted_avg_sharpe:.2f}\\n\")\n",
    "    \n",
    "    print(f\"{'=' * 80}\")\n",
    "    print(f\"Œî Score:  {weighted_avg_score - best_global_score:+.3f}\")\n",
    "    print(f\"Œî Sharpe: {weighted_avg_sharpe - best_global_sharpe:+.2f}\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    # Garde-fou #6 : D√©cision\n",
    "    if weighted_avg_score > best_global_score and abs(weighted_avg_sharpe - best_global_sharpe) <= 0.5:\n",
    "        print(\"‚úÖ GATE PASS√â: Optimisation par profil am√©liore les r√©sultats\")\n",
    "        print(\"   ‚Üí Recommandation: Adopter configs par profil\\n\")\n",
    "        RECOMMENDATION = \"profil\"\n",
    "    elif weighted_avg_score > best_global_score * 0.95:  # Tol√©rance 5%\n",
    "        print(\"‚ö†Ô∏è  GATE PARTIEL: Optimisation par profil l√©g√®rement meilleure\")\n",
    "        print(\"   ‚Üí Recommandation: √âvaluer sur 28 paires avant d√©cision finale\\n\")\n",
    "        RECOMMENDATION = \"profil_conditional\"\n",
    "    else:\n",
    "        print(\"‚ùå GATE √âCHOU√â: Optimisation globale reste meilleure\")\n",
    "        print(\"   ‚Üí Recommandation: Garder config globale unique\\n\")\n",
    "        RECOMMENDATION = \"global\"\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è  R√©sultats √âtape 1 (global) non trouv√©s\")\n",
    "    print(\"   Gate skip, adopter configs par profil par d√©faut\\n\")\n",
    "    RECOMMENDATION = \"profil\"\n",
    "    \n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"üéØ RECOMMANDATION FINALE: {RECOMMENDATION.upper()}\")\n",
    "print(f\"{'=' * 80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 configurations\n",
    "print(\"\\nüèÜ TOP 10 CONFIGURATIONS (par Test Score moyen)\\n\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "top10 = df_wf_avg.head(10)\n",
    "for idx, row in top10.iterrows():\n",
    "    print(f\"#{idx+1}\")\n",
    "    print(f\"   MA: {row['ma_window']}, Env: {row['envelopes']}, Size: {row['size']}, SL: {row['stop_loss']}, Adaptive: {row['adaptive']}\")\n",
    "    print(f\"   Train Sharpe: {row['train_sharpe']:.2f}, Test Sharpe: {row['test_sharpe']:.2f}, Consistency: {row['consistency']:.2f}\")\n",
    "    print(f\"   Train Score: {row['train_score']:.3f}, Test Score: {row['test_score']:.3f}\")\n",
    "    print(f\"   Trades: Train={row['train_trades']}, Test={row['test_trades']}\")\n",
    "    print()\n",
    "\n",
    "# Identifier le meilleur\n",
    "best_config = top10.iloc[0]\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(f\"‚úÖ MEILLEURE CONFIGURATION:\")\n",
    "print(f\"   MA: {best_config['ma_window']}\")\n",
    "print(f\"   Envelopes: {best_config['envelopes']}\")\n",
    "print(f\"   Size: {best_config['size']}\")\n",
    "print(f\"   Stop Loss: {best_config['stop_loss']}\")\n",
    "print(f\"   Adaptive: {best_config['adaptive']}\")\n",
    "print(f\"   Test Score: {best_config['test_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison Phase A (8 paires) vs Phase B (28 paires)\n",
    "print(\"üìä COMPARAISON PHASE A vs PHASE B\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Limiter √† top3 uniquement (car df_portfolio peut contenir plus de 3 configs)\n",
    "for i in range(min(len(df_portfolio), len(top3))):\n",
    "    row_portfolio = df_portfolio.iloc[i]\n",
    "    row_phase_a = top3.iloc[i]\n",
    "    \n",
    "    print(f\"\\n{row_portfolio['config']}:\")\n",
    "    print(f\"   MA={row_portfolio['ma_window']}, Env={row_portfolio['envelopes']}, Adaptive={row_portfolio['adaptive']}\")\n",
    "    print(f\"   Phase A (8 paires):  Score={row_phase_a['test_score']:.3f}, Sharpe={row_phase_a['test_sharpe']:.2f}\")\n",
    "    print(f\"   Phase B (28 paires): Score={row_portfolio['score']:.3f}, Sharpe={row_portfolio['sharpe']:.2f}\")\n",
    "    \n",
    "    # V√©rifier consistency\n",
    "    score_diff = abs(row_portfolio['score'] - row_phase_a['test_score'])\n",
    "    sharpe_diff = abs(row_portfolio['sharpe'] - row_phase_a['test_sharpe'])\n",
    "    \n",
    "    if sharpe_diff <= 0.5:\n",
    "        print(f\"   ‚úÖ ROBUSTE: Sharpe diff = {sharpe_diff:.2f} (‚â§0.5)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  DIVERGENCE: Sharpe diff = {sharpe_diff:.2f} (>0.5)\")\n",
    "\n",
    "# S√©lectionner la meilleure config pour hold-out\n",
    "best_config_portfolio = df_portfolio.iloc[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üèÜ MEILLEURE CONFIG POUR HOLD-OUT:\")\n",
    "print(f\"   {best_config_portfolio['config']}\")\n",
    "print(f\"   MA: {best_config_portfolio['ma_window']}\")\n",
    "print(f\"   Envelopes: {best_config_portfolio['envelopes']}\")\n",
    "print(f\"   Size: {best_config_portfolio['size']}\")\n",
    "print(f\"   Stop Loss: {best_config_portfolio['stop_loss']}\")\n",
    "print(f\"   Adaptive: {best_config_portfolio['adaptive']}\")\n",
    "print(f\"   Score Portfolio: {best_config_portfolio['score']:.3f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester top-3 configs sur 28 paires\n",
    "top3 = df_wf_avg.head(3)\n",
    "\n",
    "portfolio_results = []\n",
    "\n",
    "for idx, row in top3.iterrows():\n",
    "    config_name = f\"Config#{idx+1}\"\n",
    "    print(f\"\\nüîÑ Test {config_name}: MA={row['ma_window']}, Env={row['envelopes']}, Adaptive={row['adaptive']}\")\n",
    "    \n",
    "    # Pr√©parer params\n",
    "    params_coin_28 = {}\n",
    "    for pair in df_list_full_28.keys():\n",
    "        params_coin_28[pair] = {\n",
    "            \"src\": \"close\",\n",
    "            \"ma_base_window\": int(row['ma_window']),\n",
    "            \"envelopes\": eval(row['envelopes']),\n",
    "            \"size\": float(row['size']) / BACKTEST_LEVERAGE\n",
    "        }\n",
    "    \n",
    "    # Adapter\n",
    "    if row['adaptive']:\n",
    "        adapter = RegimeBasedAdapter(\n",
    "            base_params=params_coin_28,\n",
    "            regime_series=regime_series_full_28,\n",
    "            regime_params=DEFAULT_PARAMS,\n",
    "            multipliers={'envelope_std': True},\n",
    "            base_std=0.10\n",
    "        )\n",
    "    else:\n",
    "        adapter = FixedParamsAdapter(params_coin_28)\n",
    "    \n",
    "    # Run backtest\n",
    "    result = run_single_backtest(\n",
    "        df_list_full_28, oldest_pair_28, params_coin_28,\n",
    "        float(row['stop_loss']), adapter\n",
    "    )\n",
    "    \n",
    "    # M√©triques\n",
    "    final_wallet = result['wallet']\n",
    "    sharpe = result.get('sharpe_ratio', 0)\n",
    "    n_trades = len(result['trades'])\n",
    "    \n",
    "    # Score composite (comme Phase A)\n",
    "    score = calculate_composite_score(result)\n",
    "    \n",
    "    portfolio_results.append({\n",
    "        'config': config_name,\n",
    "        'ma_window': int(row['ma_window']),\n",
    "        'envelopes': row['envelopes'],\n",
    "        'size': float(row['size']),\n",
    "        'stop_loss': float(row['stop_loss']),\n",
    "        'adaptive': bool(row['adaptive']),\n",
    "        'wallet': final_wallet,\n",
    "        'sharpe': sharpe,\n",
    "        'n_trades': n_trades,\n",
    "        'score': score,\n",
    "    })\n",
    "    \n",
    "    print(f\"   Wallet: ${final_wallet:.2f}, Sharpe: {sharpe:.2f}, Trades: {n_trades}, Score: {score:.3f}\")\n",
    "\n",
    "df_portfolio = pd.DataFrame(portfolio_results).sort_values('score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Validation portfolio compl√©t√©e\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger donn√©es pour 28 paires\n",
    "df_list_full_28 = {}\n",
    "print(\"\\nüì• Chargement des 28 paires...\")\n",
    "for pair in tqdm(PAIRS_FULL, desc=\"Paires\"):\n",
    "    try:\n",
    "         # IMPORTANT: Charger jusqu'√† la fin pour avoir les donn√©es hold-out\n",
    "        df = exchange.load_data(pair, \"1h\", start_date=\"2020-01-01\", end_date=\"2025-10-03\")\n",
    "        df_list_full_28[pair] = df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è  {pair} non disponible, ignor√©\")\n",
    "\n",
    "oldest_pair_28 = min(df_list_full_28, key=lambda p: df_list_full_28[p].index.min())\n",
    "\n",
    "# R√©gimes sur BTC (m√™me p√©riode)\n",
    "df_btc_full_28 = exchange.load_data(\"BTC/USDT:USDT\", \"1h\", \n",
    "                                     start_date=PERIODS['train_full']['start'], \n",
    "                                     end_date=PERIODS['train_full']['end'])\n",
    "regime_series_full_28 = calculate_regime_series(df_btc_full_28, confirm_n=12)\n",
    "\n",
    "print(f\"\\n‚úÖ {len(df_list_full_28)} paires charg√©es (sur 28 demand√©es)\")\n",
    "print(f\"   P√©riode: 2020-01-01 ‚Üí 2025-10-03 (couvre tous les cycles)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paires compl√®tes du live bot (28 paires)\n",
    "PAIRS_FULL = [\n",
    "    \"BTC/USDT:USDT\", \"ETH/USDT:USDT\", \"BNB/USDT:USDT\", \"SOL/USDT:USDT\",\n",
    "    \"XRP/USDT:USDT\", \"DOGE/USDT:USDT\", \"ADA/USDT:USDT\", \"AVAX/USDT:USDT\",\n",
    "    \"SHIB/USDT:USDT\", \"DOT/USDT:USDT\", \"LINK/USDT:USDT\", \"MATIC/USDT:USDT\",\n",
    "    \"UNI/USDT:USDT\", \"ATOM/USDT:USDT\", \"LTC/USDT:USDT\", \"ETC/USDT:USDT\",\n",
    "    \"APT/USDT:USDT\", \"ARB/USDT:USDT\", \"OP/USDT:USDT\", \"NEAR/USDT:USDT\",\n",
    "    \"FIL/USDT:USDT\", \"INJ/USDT:USDT\", \"IMX/USDT:USDT\", \"RUNE/USDT:USDT\",\n",
    "    \"SUSHI/USDT:USDT\", \"TRX/USDT:USDT\", \"AAVE/USDT:USDT\", \"CRV/USDT:USDT\",\n",
    "]\n",
    "\n",
    "print(f\"üìä PHASE B - VALIDATION PORTFOLIO COMPLET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"   Paires: {len(PAIRS_FULL)} (portfolio complet)\")\n",
    "print(f\"   P√©riode: {PERIODS['train_full']['start']} ‚Üí {PERIODS['train_full']['end']} (BULL 2020-21, BEAR 2022, RECOVERY 2023, BULL 2024)\")\n",
    "print(f\"   Top configs √† tester: 3\")\n",
    "print(f\"\\n‚ö†Ô∏è  Cette phase valide que les configs tiennent sur le portfolio complet\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5Ô∏è‚É£ Phase B - Validation Portfolio complet (28 paires)\n",
    "\n",
    "Teste le **top-3** des configs sur les **28 paires compl√®tes** (m√™me p√©riode train) pour v√©rifier que les r√©sultats tiennent sur le portfolio complet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Validation Hold-out finale\n",
    "\n",
    "Test **UNE SEULE FOIS** sur les donn√©es de hold-out (2024 H2) pour v√©rifier qu'il n'y a pas d'overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚ö†Ô∏è  VALIDATION HOLD-OUT FINALE (28 paires)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"P√©riode: {PERIODS['holdout']['start']} ‚Üí {PERIODS['holdout']['end']}\")\n",
    "print(f\"‚ö†Ô∏è  Cette validation ne peut √™tre ex√©cut√©e qu'UNE SEULE FOIS !\\n\")\n",
    "\n",
    "# Filtrer donn√©es hold-out (28 paires)\n",
    "df_list_holdout_28 = filter_df_list_by_dates(df_list_full_28, PERIODS['holdout']['start'], PERIODS['holdout']['end'])\n",
    "df_btc_holdout = exchange.load_data(\"BTC/USDT:USDT\", \"1h\", \n",
    "                                     start_date=PERIODS['holdout']['start'], \n",
    "                                     end_date=PERIODS['holdout']['end'])\n",
    "regime_holdout = calculate_regime_series(df_btc_holdout, confirm_n=12)\n",
    "\n",
    "# Utiliser la meilleure config de Phase B (portfolio complet)\n",
    "best_cfg = df_portfolio.iloc[0]  # Meilleure config selon score Phase B\n",
    "\n",
    "# Pr√©parer params pour 28 paires\n",
    "params_coin_holdout = {}\n",
    "for pair in df_list_holdout_28.keys():\n",
    "    params_coin_holdout[pair] = {\n",
    "        \"src\": \"close\",\n",
    "        \"ma_base_window\": int(best_cfg['ma_window']),\n",
    "        \"envelopes\": eval(best_cfg['envelopes']) if isinstance(best_cfg['envelopes'], str) else best_cfg['envelopes'],\n",
    "        \"size\": float(best_cfg['size']) / BACKTEST_LEVERAGE\n",
    "    }\n",
    "\n",
    "# Test hold-out\n",
    "if best_cfg['adaptive']:\n",
    "    adapter_holdout = RegimeBasedAdapter(\n",
    "        base_params=params_coin_holdout,\n",
    "        regime_series=regime_holdout,\n",
    "        regime_params=DEFAULT_PARAMS,\n",
    "        multipliers={'envelope_std': True},\n",
    "        base_std=0.10\n",
    "    )\n",
    "else:\n",
    "    adapter_holdout = FixedParamsAdapter(params_coin_holdout)\n",
    "\n",
    "bt_holdout = run_single_backtest(\n",
    "    df_list_holdout_28, oldest_pair_28, params_coin_holdout,\n",
    "    float(best_cfg['stop_loss']), adapter_holdout\n",
    ")\n",
    "\n",
    "# Calculer m√©triques hold-out\n",
    "holdout_sharpe = bt_holdout.get('sharpe_ratio', 0)\n",
    "holdout_wallet = bt_holdout['wallet']\n",
    "holdout_perf = (holdout_wallet / INITIAL_WALLET - 1) * 100\n",
    "holdout_trades = len(bt_holdout['trades'])\n",
    "\n",
    "# Comparaison avec Phase B (portfolio)\n",
    "portfolio_sharpe = best_cfg['sharpe']\n",
    "\n",
    "print(f\"\\nüìä R√âSULTATS HOLD-OUT:\")\n",
    "print(f\"   Wallet final: ${holdout_wallet:.2f}\")\n",
    "print(f\"   Performance: {holdout_perf:+.2f}%\")\n",
    "print(f\"   Sharpe Ratio: {holdout_sharpe:.2f}\")\n",
    "print(f\"   Nombre de trades: {holdout_trades}\")\n",
    "\n",
    "print(f\"\\nüìä COMPARAISON:\")\n",
    "print(f\"   Phase B Portfolio Sharpe: {portfolio_sharpe:.2f}\")\n",
    "print(f\"   Hold-out Sharpe:          {holdout_sharpe:.2f}\")\n",
    "\n",
    "# Validation\n",
    "sharpe_diff = abs(holdout_sharpe - portfolio_sharpe)\n",
    "\n",
    "if sharpe_diff <= 0.5:\n",
    "    print(f\"\\n‚úÖ VALIDATION R√âUSSIE: Hold-out Sharpe ‚âà Portfolio Sharpe (diff={sharpe_diff:.2f})\")\n",
    "    print(f\"   Pas d'overfitting d√©tect√©. Configuration robuste sur 28 paires.\")\n",
    "elif sharpe_diff <= 1.0:\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: Hold-out Sharpe diverge l√©g√®rement (diff={sharpe_diff:.2f})\")\n",
    "    print(f\"   Overfitting possible mais acceptable.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå √âCHEC: Hold-out Sharpe diverge fortement (diff={sharpe_diff:.2f})\")\n",
    "    print(f\"   Overfitting d√©tect√© ! R√©viser les param√®tres.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification des donn√©es hold-out avant le test\n",
    "print(\"üîç V√©rification des donn√©es hold-out...\")\n",
    "print(f\"Nombre de paires charg√©es: {len(df_list_holdout_28)}\")\n",
    "for pair, df in list(df_list_holdout_28.items())[:3]:\n",
    "    print(f\"   {pair}: {len(df)} barres ({df.index.min()} ‚Üí {df.index.max()})\")\n",
    "print(f\"\\nBTC r√©gime hold-out: {len(regime_holdout)} barres\")\n",
    "print(f\"R√©gimes: {regime_holdout.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ R√©sultats et visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot : Train Sharpe vs Test Sharpe\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# S√©parer Fixed et Adaptive\n",
    "df_fixed = df_wf_avg[df_wf_avg['adaptive'] == False]\n",
    "df_adaptive = df_wf_avg[df_wf_avg['adaptive'] == True]\n",
    "\n",
    "ax.scatter(df_fixed['train_sharpe'], df_fixed['test_sharpe'], \n",
    "           alpha=0.6, s=100, label='Fixed', marker='o')\n",
    "ax.scatter(df_adaptive['train_sharpe'], df_adaptive['test_sharpe'], \n",
    "           alpha=0.6, s=100, label='Adaptive', marker='^')\n",
    "\n",
    "# Ligne y=x (pas d'overfitting)\n",
    "max_sharpe = max(df_wf_avg['train_sharpe'].max(), df_wf_avg['test_sharpe'].max())\n",
    "min_sharpe = min(df_wf_avg['train_sharpe'].min(), df_wf_avg['test_sharpe'].min())\n",
    "ax.plot([min_sharpe, max_sharpe], [min_sharpe, max_sharpe], \n",
    "        'r--', alpha=0.5, label='No overfitting (y=x)')\n",
    "\n",
    "# Zone acceptable (¬±0.5)\n",
    "ax.fill_between([min_sharpe, max_sharpe], \n",
    "                 [min_sharpe - 0.5, max_sharpe - 0.5],\n",
    "                 [min_sharpe + 0.5, max_sharpe + 0.5],\n",
    "                 alpha=0.1, color='green', label='Acceptable zone (¬±0.5)')\n",
    "\n",
    "ax.set_xlabel('Train Sharpe Ratio', fontsize=12)\n",
    "ax.set_ylabel('Test Sharpe Ratio', fontsize=12)\n",
    "ax.set_title('Train vs Test Sharpe Ratio (Overfitting Detection)', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'train_vs_test_sharpe_{timestamp}.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Graphique sauvegard√©: train_vs_test_sharpe_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart : Top 10 configurations par test score\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "top10_display = df_wf_avg.head(10).copy()\n",
    "top10_display['config_label'] = (\n",
    "    'MA=' + top10_display['ma_window'].astype(str) + \n",
    "    ', Size=' + top10_display['size'].astype(str) +\n",
    "    ', ' + top10_display['adaptive'].map({True: 'Adapt', False: 'Fixed'})\n",
    ")\n",
    "\n",
    "x = range(len(top10_display))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar([i - width/2 for i in x], top10_display['train_score'], \n",
    "               width, label='Train Score', alpha=0.8, color='steelblue')\n",
    "bars2 = ax.bar([i + width/2 for i in x], top10_display['test_score'], \n",
    "               width, label='Test Score', alpha=0.8, color='coral')\n",
    "\n",
    "ax.set_xlabel('Configuration', fontsize=12)\n",
    "ax.set_ylabel('Composite Score', fontsize=12)\n",
    "ax.set_title('Top 10 Configurations by Test Score', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top10_display['config_label'], rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'top10_scores_{timestamp}.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Graphique sauvegard√©: top10_scores_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder tous les r√©sultats\n",
    "df_wf_results.to_csv(f\"wf_results_detailed_{timestamp}.csv\", index=False)\n",
    "df_wf_avg.to_csv(f\"wf_results_summary_{timestamp}.csv\", index=False)\n",
    "\n",
    "# Sauvegarder meilleure config en JSON\n",
    "import json\n",
    "\n",
    "best_config_export = {\n",
    "    \"ma_base_window\": int(best_config['ma_window']),\n",
    "    \"envelopes\": eval(best_config['envelopes']),\n",
    "    \"size\": float(best_config['size']),\n",
    "    \"stop_loss\": float(best_config['stop_loss']),\n",
    "    \"adaptive\": bool(best_config['adaptive']),\n",
    "    \"train_sharpe\": float(best_config['train_sharpe']),\n",
    "    \"test_sharpe\": float(best_config['test_sharpe']),\n",
    "    \"test_score\": float(best_config['test_score']),\n",
    "    \"holdout_sharpe\": float(holdout_sharpe),\n",
    "    \"holdout_perf\": float(holdout_perf),\n",
    "    \"timestamp\": timestamp,\n",
    "}\n",
    "\n",
    "with open(f\"best_config_{timestamp}.json\", 'w') as f:\n",
    "    json.dump(best_config_export, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ R√©sultats sauvegard√©s:\")\n",
    "print(f\"   - wf_results_detailed_{timestamp}.csv (tous les backtests)\")\n",
    "print(f\"   - wf_results_summary_{timestamp}.csv (moyennes par config)\")\n",
    "print(f\"   - best_config_{timestamp}.json (meilleure configuration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Recommandation finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ RECOMMANDATION FINALE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Utiliser df_portfolio directement\n",
    "best_cfg_final = df_portfolio.iloc[0]\n",
    "\n",
    "print(f\"\\n‚úÖ Meilleure configuration identifi√©e (valid√©e sur 28 paires):\")\n",
    "print(f\"   Config: {best_cfg_final['config']}\")\n",
    "print(f\"   ma_base_window: {best_cfg_final['ma_window']}\")\n",
    "print(f\"   envelopes: {best_cfg_final['envelopes']}\")\n",
    "print(f\"   size: {best_cfg_final['size']}\")\n",
    "print(f\"   stop_loss: {best_cfg_final['stop_loss']}\")\n",
    "print(f\"   adaptive: {best_cfg_final['adaptive']}\")\n",
    "\n",
    "print(f\"\\nüìä Performance valid√©e:\")\n",
    "print(f\"   Phase A (8 paires) - Test Score: {top3.iloc[0]['test_score']:.3f}, Sharpe: {top3.iloc[0]['test_sharpe']:.2f}\")\n",
    "print(f\"   Phase B (28 paires) - Score: {best_cfg_final['score']:.3f}, Sharpe: {best_cfg_final['sharpe']:.2f}\")\n",
    "print(f\"   Hold-out (28 paires) - Sharpe: {holdout_sharpe:.2f}, Perf: {holdout_perf:+.2f}%\")\n",
    "\n",
    "if sharpe_diff <= 0.5:\n",
    "    print(f\"\\n‚úÖ Validation: Configuration robuste (pas d'overfitting)\")\n",
    "    print(f\"   ‚úì Test√©e sur 8 paires (Walk-Forward)\")\n",
    "    print(f\"   ‚úì Valid√©e sur 28 paires (Phase B)\")\n",
    "    print(f\"   ‚úì Hold-out confirm√© (2024-H2)\")\n",
    "    print(f\"   ‚Üí RECOMMAND√â pour mise en production\")\n",
    "elif sharpe_diff <= 1.0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Validation: Overfitting l√©ger d√©tect√©\")\n",
    "    print(f\"   ‚Üí Utiliser avec prudence, surveiller en live\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Validation: Overfitting significatif\")\n",
    "    print(f\"   ‚Üí NE PAS utiliser en production\")\n",
    "    print(f\"   ‚Üí R√©duire la complexit√© du grid ou augmenter les donn√©es\")\n",
    "\n",
    "print(f\"\\nüìù Prochaines √©tapes:\")\n",
    "print(f\"   1. Appliquer la config dans multi_envelope.ipynb (28 paires)\")\n",
    "print(f\"   2. Valider sur paper trading / forward test\")\n",
    "print(f\"   3. Si r√©sultats conformes ‚Üí D√©ployer en production\")\n",
    "\n",
    "print(f\"\\nüí° Note:\")\n",
    "print(f\"   Cette config a √©t√© optimis√©e sur un √©chantillon stratifi√© (8 paires)\")\n",
    "print(f\"   puis valid√©e sur le portfolio complet (28 paires) + hold-out.\")\n",
    "print(f\"   M√©thodologie robuste anti-overfitting.\")\n",
    "print(f\"\\n‚ö†Ô∏è  IMPORTANT: Param√®tres GLOBAUX (identiques pour toutes les cryptos)\")\n",
    "print(f\"   Pour optimiser par profil (majors/mid-caps/volatiles/low), voir Option 1\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL-21b : GATE V2 HI√âRARCHIQUE ===\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GATE V2 : VALIDATION MULTI-NIVEAUX\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculer m√©triques globales\n",
    "weighted_avg_score = (df_profile_scores['score'] * df_profile_scores['weight']).sum() / df_profile_scores['weight'].sum()\n",
    "weighted_avg_sharpe = (df_profile_scores['sharpe'] * df_profile_scores['weight']).sum() / df_profile_scores['weight'].sum()\n",
    "\n",
    "# M√©triques de r√©f√©rence (optimisation globale √âtape 1)\n",
    "best_global_score = 2.943\n",
    "best_global_sharpe = 3.13\n",
    "\n",
    "# TIER 1 : HARD GATES (doivent passer)\n",
    "tier1_trades = df_portfolio_total_trades >= 200\n",
    "tier1_holdout = abs(weighted_avg_sharpe - best_global_sharpe) <= 0.7\n",
    "\n",
    "tier1_pass = tier1_trades and tier1_holdout\n",
    "\n",
    "print(f\"\\nTIER 1 (HARD) :\")\n",
    "print(f\"  [{'‚úÖ' if tier1_trades else '‚ùå'}] Trades >= 200 : {df_portfolio_total_trades}\")\n",
    "print(f\"  [{'‚úÖ' if tier1_holdout else '‚ùå'}] |Œî Sharpe holdout| <= 0.7 : {abs(weighted_avg_sharpe - best_global_sharpe):.2f}\")\n",
    "\n",
    "if not tier1_pass:\n",
    "    print(\"\\n‚ùå TIER 1 √âCHOU√â - Gate rejet√©\")\n",
    "    RECOMMENDATION = \"global\"\n",
    "else:\n",
    "    # TIER 2 : SOFT GATES (2 sur 3 suffisent)\n",
    "    tier2_score = weighted_avg_score > best_global_score\n",
    "    tier2_sharpe = weighted_avg_sharpe > best_global_sharpe\n",
    "    tier2_consistency = abs(sharpe_train_avg - sharpe_test_avg) <= 0.5\n",
    "\n",
    "    tier2_pass = sum([tier2_score, tier2_sharpe, tier2_consistency]) >= 2\n",
    "\n",
    "    print(f\"\\nTIER 2 (SOFT - 2/3 requis) :\")\n",
    "    print(f\"  [{'‚úÖ' if tier2_score else '‚ùå'}] Score > Global : {weighted_avg_score:.2f} vs {best_global_score:.2f}\")\n",
    "    print(f\"  [{'‚úÖ' if tier2_sharpe else '‚ùå'}] Sharpe > Global : {weighted_avg_sharpe:.2f} vs {best_global_sharpe:.2f}\")\n",
    "    print(f\"  [{'‚úÖ' if tier2_consistency else '‚ùå'}] |Œî Sharpe train-test| <= 0.5 : {abs(sharpe_train_avg - sharpe_test_avg):.2f}\")\n",
    "    print(f\"  ‚Üí Passed: {sum([tier2_score, tier2_sharpe, tier2_consistency])}/3\")\n",
    "\n",
    "    # TIER 3 : WARNING (log only)\n",
    "    tier3_phase = abs(sharpe_phaseA - sharpe_phaseB) <= 0.5\n",
    "\n",
    "    print(f\"\\nTIER 3 (WARNING) :\")\n",
    "    print(f\"  [{'‚úÖ' if tier3_phase else '‚ö†Ô∏è '}] |Œî Sharpe Phase A-B| <= 0.5 : {abs(sharpe_phaseA - sharpe_phaseB):.2f}\")\n",
    "\n",
    "    # D√©cision finale\n",
    "    if tier2_pass:\n",
    "        RECOMMENDATION = \"profil\"\n",
    "        print(\"\\n‚úÖ GATE V2 VALID√â - Utiliser optimisation par profils\")\n",
    "    else:\n",
    "        RECOMMENDATION = \"global\"\n",
    "        print(\"\\n‚ùå GATE V2 √âCHOU√â - Utiliser optimisation globale\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"RECOMMANDATION FINALE : {RECOMMENDATION.upper()}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sauvegarder r√©sultats\n",
    "results_final = {\n",
    "    'recommendation': RECOMMENDATION,\n",
    "    'weighted_score_profile': weighted_avg_score,\n",
    "    'weighted_sharpe_profile': weighted_avg_sharpe,\n",
    "    'score_global': best_global_score,\n",
    "    'sharpe_global': best_global_sharpe,\n",
    "    'tier1_pass': tier1_pass,\n",
    "    'tier2_pass': tier2_pass if tier1_pass else False,\n",
    "    'tier3_pass': tier3_phase,\n",
    "    'timestamp': pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "}\n",
    "\n",
    "# Exporter\n",
    "import json\n",
    "output_file = f\"gate_v2_result_{results_final['timestamp']}.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results_final, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ R√©sultats sauvegard√©s : {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
