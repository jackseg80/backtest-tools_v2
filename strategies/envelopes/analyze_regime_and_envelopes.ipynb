{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse par R√©gime : Adaptive vs Fixed\n",
    "\n",
    "**Objectif** : Comprendre o√π et pourquoi l'optimisation Adaptive sous-performe vs Fixed.\n",
    "\n",
    "**M√©thodologie** :\n",
    "1. Charger les r√©sultats Walk-Forward existants\n",
    "2. D√©couper les performances par r√©gime (Bull 2020, Bear 2022, Recovery 2023, Bull 2024)\n",
    "3. G√©n√©rer heatmaps Œî(Adaptive - Fixed) par r√©gime √ó profil\n",
    "4. Identifier les r√©gimes/profils o√π Adaptive perd\n",
    "\n",
    "**Donn√©es** : R√©sultats de `optimize_multi_envelope.ipynb` (d√©j√† calcul√©s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "print(\"‚úÖ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des R√©sultats Existants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver le fichier de r√©sultats le plus r√©cent\n",
    "results_dir = Path('.')\n",
    "wf_files = sorted(results_dir.glob('wf_results_detailed_*.csv'), reverse=True)\n",
    "\n",
    "if len(wf_files) == 0:\n",
    "    print(\"‚ùå ERREUR: Aucun fichier wf_results_detailed_*.csv trouv√©\")\n",
    "    print(\"   Vous devez d'abord ex√©cuter optimize_multi_envelope.ipynb en MODE PRODUCTION\")\n",
    "    raise FileNotFoundError(\"No optimization results found\")\n",
    "\n",
    "latest_file = wf_files[0]\n",
    "print(f\"üìÇ Fichier de r√©sultats : {latest_file.name}\")\n",
    "print(f\"   Date : {latest_file.stat().st_mtime}\")\n",
    "\n",
    "# Charger les r√©sultats\n",
    "df_wf = pd.read_csv(latest_file)\n",
    "\n",
    "print(f\"\\n‚úÖ {len(df_wf)} r√©sultats charg√©s\")\n",
    "print(f\"   Colonnes : {list(df_wf.columns)}\")\n",
    "print(f\"\\nAper√ßu :\")\n",
    "df_wf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. D√©finition des R√©gimes\n",
    "\n",
    "P√©riodes de march√© bas√©es sur les cycles BTC :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition des r√©gimes (dates exactes des cycles Bitcoin)\n",
    "REGIMES = {\n",
    "    'bull_2020': {\n",
    "        'start': '2020-03-13',\n",
    "        'end': '2021-11-10',\n",
    "        'label': 'Bull 2020-2021',\n",
    "        'desc': 'COVID bottom $3,850 ‚Üí ATH $69,000'\n",
    "    },\n",
    "    'bear_2022': {\n",
    "        'start': '2021-11-10',\n",
    "        'end': '2022-11-21',\n",
    "        'label': 'Bear 2021-2022',\n",
    "        'desc': 'ATH $69k ‚Üí FTX crash $15,479'\n",
    "    },\n",
    "    'recovery_2023': {\n",
    "        'start': '2022-11-22',\n",
    "        'end': '2023-12-31',\n",
    "        'label': 'Recovery 2023',\n",
    "        'desc': 'FTX bottom $16k ‚Üí Recovery $42k'\n",
    "    },\n",
    "    'bull_2024': {\n",
    "        'start': '2024-01-01',\n",
    "        'end': '2024-10-03',\n",
    "        'label': 'Bull 2024',\n",
    "        'desc': 'ETF approval ‚Üí ATH $73,800'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"R√©gimes d√©finis :\")\n",
    "for regime_id, info in REGIMES.items():\n",
    "    print(f\"  {info['label']:20s} : {info['start']} ‚Üí {info['end']}\")\n",
    "    print(f\"  {'':20s}   {info['desc']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse Exploratoire des R√©sultats\n",
    "\n",
    "Comprendre la structure des donn√©es avant analyse par r√©gime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier la structure des r√©sultats\n",
    "print(\"=\" * 80)\n",
    "print(\"STRUCTURE DES R√âSULTATS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Colonnes disponibles\n",
    "print(f\"\\nColonnes disponibles : {len(df_wf.columns)}\")\n",
    "for col in df_wf.columns:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "# Profils test√©s\n",
    "if 'profile' in df_wf.columns:\n",
    "    print(f\"\\nProfils : {df_wf['profile'].unique().tolist()}\")\n",
    "    print(f\"  Counts : {df_wf['profile'].value_counts().to_dict()}\")\n",
    "\n",
    "# Adaptive vs Fixed\n",
    "if 'adaptive' in df_wf.columns:\n",
    "    print(f\"\\nAdaptive :\")\n",
    "    print(f\"  True  : {(df_wf['adaptive'] == True).sum()} configs\")\n",
    "    print(f\"  False : {(df_wf['adaptive'] == False).sum()} configs\")\n",
    "\n",
    "# Folds\n",
    "if 'fold' in df_wf.columns:\n",
    "    print(f\"\\nFolds : {sorted(df_wf['fold'].unique())}\")\n",
    "\n",
    "# Statistiques Sharpe\n",
    "if 'sharpe_test' in df_wf.columns:\n",
    "    print(f\"\\nSharpe Test :\")\n",
    "    print(f\"  Mean   : {df_wf['sharpe_test'].mean():.2f}\")\n",
    "    print(f\"  Median : {df_wf['sharpe_test'].median():.2f}\")\n",
    "    print(f\"  Std    : {df_wf['sharpe_test'].std():.2f}\")\n",
    "    print(f\"  Min    : {df_wf['sharpe_test'].min():.2f}\")\n",
    "    print(f\"  Max    : {df_wf['sharpe_test'].max():.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparaison Adaptive vs Fixed (Global)\n",
    "\n",
    "Avant d'analyser par r√©gime, regardons la diff√©rence globale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison globale Adaptive vs Fixed\n",
    "if 'adaptive' in df_wf.columns and 'sharpe_test' in df_wf.columns:\n",
    "    \n",
    "    df_fixed = df_wf[df_wf['adaptive'] == False]\n",
    "    df_adaptive = df_wf[df_wf['adaptive'] == True]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPARAISON GLOBALE : ADAPTIVE vs FIXED\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    metrics = ['sharpe_test', 'sharpe_train', 'score_test', 'n_trades_test']\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': [],\n",
    "        'Fixed (Mean)': [],\n",
    "        'Adaptive (Mean)': [],\n",
    "        'Œî (Adaptive - Fixed)': [],\n",
    "        'Œî %': []\n",
    "    })\n",
    "    \n",
    "    for metric in metrics:\n",
    "        if metric in df_wf.columns:\n",
    "            fixed_mean = df_fixed[metric].mean()\n",
    "            adaptive_mean = df_adaptive[metric].mean()\n",
    "            delta = adaptive_mean - fixed_mean\n",
    "            delta_pct = (delta / fixed_mean * 100) if fixed_mean != 0 else 0\n",
    "            \n",
    "            comparison = pd.concat([comparison, pd.DataFrame({\n",
    "                'Metric': [metric],\n",
    "                'Fixed (Mean)': [f\"{fixed_mean:.2f}\"],\n",
    "                'Adaptive (Mean)': [f\"{adaptive_mean:.2f}\"],\n",
    "                'Œî (Adaptive - Fixed)': [f\"{delta:+.2f}\"],\n",
    "                'Œî %': [f\"{delta_pct:+.1f}%\"]\n",
    "            })], ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\", comparison.to_string(index=False))\n",
    "    \n",
    "    # Verdict\n",
    "    sharpe_delta = df_adaptive['sharpe_test'].mean() - df_fixed['sharpe_test'].mean()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    if sharpe_delta > 0:\n",
    "        print(f\"‚úÖ Adaptive GAGNE : Sharpe +{sharpe_delta:.2f} ({sharpe_delta/df_fixed['sharpe_test'].mean()*100:+.1f}%)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Adaptive PERD : Sharpe {sharpe_delta:.2f} ({sharpe_delta/df_fixed['sharpe_test'].mean()*100:+.1f}%)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Colonnes 'adaptive' ou 'sharpe_test' manquantes - skip comparaison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse par R√©gime\n",
    "\n",
    "**IMPORTANT** : Cette analyse n√©cessite les donn√©es `df_days` individuelles par backtest, qui ne sont pas stock√©es dans `wf_results_detailed.csv`.\n",
    "\n",
    "**Deux options** :\n",
    "1. **Option A (Lecture directe)** : Si les pickles/parquets de r√©sultats sont sauvegard√©s\n",
    "2. **Option B (Re-calcul)** : Re-lancer les backtests des meilleures configs et analyser df_days\n",
    "\n",
    "Pour l'instant, analysons ce qu'on peut avec les donn√©es agr√©g√©es disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier si on a les donn√©es temporelles pour d√©couper par r√©gime\n",
    "temporal_cols = ['start_date', 'end_date', 'test_start', 'test_end', 'train_start', 'train_end']\n",
    "available_temporal = [col for col in temporal_cols if col in df_wf.columns]\n",
    "\n",
    "print(f\"Colonnes temporelles disponibles : {available_temporal}\")\n",
    "\n",
    "if len(available_temporal) > 0:\n",
    "    print(\"\\n‚úÖ Analyse par r√©gime possible via mapping folds ‚Üí r√©gimes\")\n",
    "    print(\"   √âtape suivante : Mapper chaque fold √† son r√©gime dominant\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Pas de colonnes temporelles - analyse par r√©gime limit√©e\")\n",
    "    print(\"   Solution : Re-lancer backtests des meilleures configs avec sauvegarde df_days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyse par Profil\n",
    "\n",
    "En attendant l'analyse temporelle compl√®te, analysons par profil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse Adaptive vs Fixed par profil\n",
    "if 'profile' in df_wf.columns and 'adaptive' in df_wf.columns:\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"COMPARAISON PAR PROFIL : ADAPTIVE vs FIXED\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    profiles = df_wf['profile'].unique()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for profile in profiles:\n",
    "        df_profile = df_wf[df_wf['profile'] == profile]\n",
    "        \n",
    "        df_fixed_prof = df_profile[df_profile['adaptive'] == False]\n",
    "        df_adaptive_prof = df_profile[df_profile['adaptive'] == True]\n",
    "        \n",
    "        if len(df_fixed_prof) > 0 and len(df_adaptive_prof) > 0:\n",
    "            sharpe_fixed = df_fixed_prof['sharpe_test'].mean()\n",
    "            sharpe_adaptive = df_adaptive_prof['sharpe_test'].mean()\n",
    "            delta_sharpe = sharpe_adaptive - sharpe_fixed\n",
    "            delta_pct = (delta_sharpe / sharpe_fixed * 100) if sharpe_fixed != 0 else 0\n",
    "            \n",
    "            n_trades_fixed = df_fixed_prof['n_trades_test'].mean()\n",
    "            n_trades_adaptive = df_adaptive_prof['n_trades_test'].mean()\n",
    "            \n",
    "            results.append({\n",
    "                'Profil': profile,\n",
    "                'Sharpe Fixed': f\"{sharpe_fixed:.2f}\",\n",
    "                'Sharpe Adaptive': f\"{sharpe_adaptive:.2f}\",\n",
    "                'Œî Sharpe': f\"{delta_sharpe:+.2f}\",\n",
    "                'Œî %': f\"{delta_pct:+.1f}%\",\n",
    "                'Trades Fixed': f\"{n_trades_fixed:.0f}\",\n",
    "                'Trades Adaptive': f\"{n_trades_adaptive:.0f}\",\n",
    "                'Verdict': '‚úÖ Adaptive' if delta_sharpe > 0 else '‚ùå Fixed'\n",
    "            })\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(\"\\n\", df_results.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"R√âSUM√â\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    adaptive_wins = sum([1 for r in results if '‚úÖ' in r['Verdict']])\n",
    "    print(f\"  Adaptive gagne sur {adaptive_wins}/{len(results)} profils\")\n",
    "    \n",
    "    if adaptive_wins < len(results) / 2:\n",
    "        print(f\"\\n‚ùå Conclusion : Adaptive perd sur la majorit√© des profils\")\n",
    "        print(f\"   ‚Üí L'approche Fixed reste meilleure globalement\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Conclusion : Adaptive gagne sur la majorit√© des profils\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Colonnes 'profile' ou 'adaptive' manquantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisation : Heatmap Œî(Adaptive - Fixed) par Profil\n",
    "\n",
    "Heatmap montrant o√π Adaptive gagne (vert) ou perd (rouge) vs Fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap Œî Sharpe par profil\n",
    "if 'profile' in df_wf.columns and 'adaptive' in df_wf.columns:\n",
    "    \n",
    "    # Pr√©parer donn√©es pour heatmap\n",
    "    profiles = sorted(df_wf['profile'].unique())\n",
    "    metrics = ['sharpe_test', 'score_test', 'n_trades_test']\n",
    "    \n",
    "    delta_data = []\n",
    "    \n",
    "    for profile in profiles:\n",
    "        row = {'Profil': profile}\n",
    "        \n",
    "        df_profile = df_wf[df_wf['profile'] == profile]\n",
    "        df_fixed = df_profile[df_profile['adaptive'] == False]\n",
    "        df_adaptive = df_profile[df_profile['adaptive'] == True]\n",
    "        \n",
    "        for metric in metrics:\n",
    "            if metric in df_wf.columns:\n",
    "                fixed_val = df_fixed[metric].mean()\n",
    "                adaptive_val = df_adaptive[metric].mean()\n",
    "                delta = adaptive_val - fixed_val\n",
    "                row[metric] = delta\n",
    "        \n",
    "        delta_data.append(row)\n",
    "    \n",
    "    df_delta = pd.DataFrame(delta_data).set_index('Profil')\n",
    "    \n",
    "    # Plot heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    sns.heatmap(\n",
    "        df_delta,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap='RdYlGn',\n",
    "        center=0,\n",
    "        cbar_kws={'label': 'Œî (Adaptive - Fixed)'},\n",
    "        linewidths=0.5,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Heatmap Œî(Adaptive - Fixed) par Profil', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('M√©trique', fontsize=12)\n",
    "    ax.set_ylabel('Profil', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('heatmap_adaptive_vs_fixed_by_profile.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Heatmap sauvegard√©e : heatmap_adaptive_vs_fixed_by_profile.png\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Donn√©es insuffisantes pour heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Diagnostic et Recommandations\n",
    "\n",
    "Synth√®se des findings et prochaines √©tapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DIAGNOSTIC FINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "findings = []\n",
    "\n",
    "# Finding 1: Adaptive vs Fixed global\n",
    "if 'adaptive' in df_wf.columns:\n",
    "    df_fixed = df_wf[df_wf['adaptive'] == False]\n",
    "    df_adaptive = df_wf[df_wf['adaptive'] == True]\n",
    "    \n",
    "    sharpe_delta = df_adaptive['sharpe_test'].mean() - df_fixed['sharpe_test'].mean()\n",
    "    \n",
    "    if sharpe_delta < -0.1:\n",
    "        findings.append({\n",
    "            'Finding': 'Adaptive sous-performe globalement',\n",
    "            'Impact': f'Sharpe {sharpe_delta:.2f}',\n",
    "            'Recommendation': 'Utiliser Fixed params (pas de r√©gime adaptation)'\n",
    "        })\n",
    "    elif sharpe_delta > 0.1:\n",
    "        findings.append({\n",
    "            'Finding': 'Adaptive sur-performe globalement',\n",
    "            'Impact': f'Sharpe +{sharpe_delta:.2f}',\n",
    "            'Recommendation': 'Utiliser Adaptive params (avec r√©gimes)'\n",
    "        })\n",
    "    else:\n",
    "        findings.append({\n",
    "            'Finding': 'Adaptive ‚âà Fixed (performance similaire)',\n",
    "            'Impact': f'Sharpe Œî {sharpe_delta:.2f}',\n",
    "            'Recommendation': 'Utiliser Fixed (plus simple, m√™me r√©sultat)'\n",
    "        })\n",
    "\n",
    "# Finding 2: Nombre de trades\n",
    "if 'n_trades_test' in df_wf.columns:\n",
    "    avg_trades = df_wf['n_trades_test'].mean()\n",
    "    \n",
    "    if avg_trades < 50:\n",
    "        findings.append({\n",
    "            'Finding': '√âchantillon de trades insuffisant',\n",
    "            'Impact': f'Moyenne {avg_trades:.0f} trades/config',\n",
    "            'Recommendation': '√âlargir fen√™tres envelopes ou r√©duire MA'\n",
    "        })\n",
    "\n",
    "# Finding 3: Profils probl√©matiques\n",
    "if 'profile' in df_wf.columns:\n",
    "    for profile in df_wf['profile'].unique():\n",
    "        df_prof = df_wf[df_wf['profile'] == profile]\n",
    "        \n",
    "        if 'n_trades_test' in df_prof.columns:\n",
    "            if df_prof['n_trades_test'].mean() < 30:\n",
    "                findings.append({\n",
    "                    'Finding': f'Profil \"{profile}\" : trop peu de trades',\n",
    "                    'Impact': f'{df_prof[\"n_trades_test\"].mean():.0f} trades en moyenne',\n",
    "                    'Recommendation': f'Fusionner avec autre profil ou ajuster params'\n",
    "                })\n",
    "\n",
    "# Afficher findings\n",
    "if len(findings) > 0:\n",
    "    df_findings = pd.DataFrame(findings)\n",
    "    print(\"\\n\", df_findings.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n‚úÖ Aucun probl√®me majeur d√©tect√©\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROCHAINES √âTAPES\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. **√âtape 1b** : Calculer volatilit√© r√©alis√©e par pair ‚Üí mapping nb envelopes\n",
    "   \n",
    "2. **√âtape 2a** : Re-optimisation avec multiplicateurs + nb envelopes variable\n",
    "   - Grilles r√©duites (multiplicateurs au lieu de valeurs absolues)\n",
    "   - 3 env pour majors/low, 4 env pour mid-cap/volatiles\n",
    "   - Scoring corrig√© (exclusions au lieu de p√©nalit√©s -500)\n",
    "   \n",
    "3. **√âtape 2b** : Analyse 3env vs 4env post-optimisation\n",
    "   - Valider hypoth√®se \"4env meilleur sur volatiles\"\n",
    "   \n",
    "4. **√âtape 3** : Gate v2 hi√©rarchique pour d√©cision finale\n",
    "   - Tier 1 (HARD) + Tier 2 (SOFT) moins restrictifs\n",
    "   - Recommandation Global vs Profils\n",
    "\"\"\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
