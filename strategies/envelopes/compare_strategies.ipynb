{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison Multi-Strat√©gies : Fixed vs Adaptive\n",
    "\n",
    "Ce notebook permet de comparer plusieurs configurations de la strat√©gie Envelope :\n",
    "- **Baseline** : Param√®tres fixes (configuration actuelle)\n",
    "- **Regime Adaptive** : Adaptation selon le r√©gime de march√© (BULL/BEAR/RECOVERY)\n",
    "- **Custom** : Vos propres adaptations\n",
    "\n",
    "Le syst√®me g√©n√®re automatiquement un rapport comparatif avec recommandation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuration et chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacks\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Backtest engine\n",
    "from utilities.strategies.envelopeMulti_v2 import EnvelopeMulti_v2\n",
    "from utilities.data_manager import ExchangeDataManager\n",
    "\n",
    "# Syst√®me adaptatif\n",
    "from core import calculate_regime_series, DEFAULT_PARAMS\n",
    "from core.params_adapter import FixedParamsAdapter, RegimeBasedAdapter\n",
    "from core.backtest_comparator import BacktestComparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration charg√©e\n",
      "   Paires: 8 (√©chantillon stratifi√©)\n",
      "   - Majors: 2\n",
      "   - Mid-caps: 3\n",
      "   - Volatiles: 2\n",
      "   - Low performers: 1\n",
      "   P√©riode: 2023-01-01 ‚Üí 2024-12-31\n",
      "   Leverage: 10x\n"
     ]
    }
   ],
   "source": [
    "# Configuration du backtest\n",
    "BACKTEST_LEVERAGE = 10\n",
    "START_DATE = \"2023-01-01\"\n",
    "END_DATE = \"2024-12-31\"\n",
    "\n",
    "# √âchantillon stratifi√© de 8 paires repr√©sentatives\n",
    "# (au lieu de 3 pour couvrir diff√©rents profils de march√©)\n",
    "params_live = {\n",
    "    # Majors (faible volatilit√©, r√©f√©rence march√©)\n",
    "    \"BTC/USDT:USDT\": {\"size\": 0.1, \"ma_base_window\": 7, \"envelopes\": [0.07, 0.1, 0.15]},\n",
    "    \"ETH/USDT:USDT\": {\"size\": 0.1, \"ma_base_window\": 7, \"envelopes\": [0.07, 0.1, 0.15]},\n",
    "    \n",
    "    # Mid-caps (volatilit√© moyenne)\n",
    "    \"SOL/USDT:USDT\": {\"size\": 0.1, \"ma_base_window\": 7, \"envelopes\": [0.07, 0.1, 0.15]},\n",
    "    \"AVAX/USDT:USDT\": {\"size\": 0.1, \"ma_base_window\": 7, \"envelopes\": [0.07, 0.1, 0.15]},\n",
    "    \"ADA/USDT:USDT\": {\"size\": 0.1, \"ma_base_window\": 7, \"envelopes\": [0.07, 0.1, 0.15]},\n",
    "    \n",
    "    # Volatiles (haute volatilit√©, beaucoup de trades)\n",
    "    \"DOGE/USDT:USDT\": {\"size\": 0.1, \"ma_base_window\": 7, \"envelopes\": [0.07, 0.1, 0.15]},\n",
    "    \"SUSHI/USDT:USDT\": {\"size\": 0.1, \"ma_base_window\": 7, \"envelopes\": [0.07, 0.1, 0.15]},\n",
    "    \n",
    "    # Low performers (pour tester robustesse)\n",
    "    \"TRX/USDT:USDT\": {\"size\": 0.1, \"ma_base_window\": 7, \"envelopes\": [0.07, 0.1, 0.15]},\n",
    "}\n",
    "\n",
    "# Classification par profil\n",
    "PAIR_CLASSES = {\n",
    "    \"BTC/USDT:USDT\": \"major\",\n",
    "    \"ETH/USDT:USDT\": \"major\",\n",
    "    \"SOL/USDT:USDT\": \"mid-cap\",\n",
    "    \"AVAX/USDT:USDT\": \"mid-cap\",\n",
    "    \"ADA/USDT:USDT\": \"mid-cap\",\n",
    "    \"DOGE/USDT:USDT\": \"volatile\",\n",
    "    \"SUSHI/USDT:USDT\": \"volatile\",\n",
    "    \"TRX/USDT:USDT\": \"low\",\n",
    "}\n",
    "\n",
    "# Conversion pour backtest (diviser size par leverage)\n",
    "params_coin = {}\n",
    "for pair, p in params_live.items():\n",
    "    params_coin[pair] = {\n",
    "        \"ma_base_window\": p[\"ma_base_window\"],\n",
    "        \"envelopes\": p[\"envelopes\"],\n",
    "        \"src\": \"close\",\n",
    "        \"size\": p[\"size\"] / BACKTEST_LEVERAGE  # Ajustement pour V2 engine\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Configuration charg√©e\")\n",
    "print(f\"   Paires: {len(params_coin)} (√©chantillon stratifi√©)\")\n",
    "print(f\"   - Majors: {sum(1 for c in PAIR_CLASSES.values() if c == 'major')}\")\n",
    "print(f\"   - Mid-caps: {sum(1 for c in PAIR_CLASSES.values() if c == 'mid-cap')}\")\n",
    "print(f\"   - Volatiles: {sum(1 for c in PAIR_CLASSES.values() if c == 'volatile')}\")\n",
    "print(f\"   - Low performers: {sum(1 for c in PAIR_CLASSES.values() if c == 'low')}\")\n",
    "print(f\"   P√©riode: {START_DATE} ‚Üí {END_DATE}\")\n",
    "print(f\"   Leverage: {BACKTEST_LEVERAGE}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement BTC/USDT:USDT...\n",
      "Chargement ETH/USDT:USDT...\n",
      "Chargement SOL/USDT:USDT...\n",
      "Chargement AVAX/USDT:USDT...\n",
      "Chargement ADA/USDT:USDT...\n",
      "Chargement DOGE/USDT:USDT...\n",
      "Chargement SUSHI/USDT:USDT...\n",
      "Chargement TRX/USDT:USDT...\n",
      "\n",
      "‚úÖ Donn√©es charg√©es. Paire la plus ancienne: BTC/USDT:USDT\n"
     ]
    }
   ],
   "source": [
    "# Chargement des donn√©es\n",
    "exchange = ExchangeDataManager(\n",
    "    exchange_name=\"bitget\",\n",
    "    path_download=\"../database/exchanges\"\n",
    ")\n",
    "\n",
    "df_list = {}\n",
    "for pair in params_coin.keys():\n",
    "    print(f\"Chargement {pair}...\")\n",
    "    df = exchange.load_data(pair, \"1h\", start_date=START_DATE, end_date=END_DATE)\n",
    "    df_list[pair] = df\n",
    "\n",
    "oldest_pair = min(df_list, key=lambda p: df_list[p].index.min())\n",
    "print(f\"\\n‚úÖ Donn√©es charg√©es. Paire la plus ancienne: {oldest_pair}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Distribution des r√©gimes d√©tect√©s:\n",
      "   BULL: 50.7%\n",
      "   BEAR: 36.4%\n",
      "   RECOVERY: 13.0%\n"
     ]
    }
   ],
   "source": [
    "# D√©tection du r√©gime sur BTC (proxy global)\n",
    "df_btc = exchange.load_data(\"BTC/USDT:USDT\", \"1h\", start_date=START_DATE, end_date=END_DATE)\n",
    "regime_series = calculate_regime_series(df_btc, confirm_n=12)\n",
    "\n",
    "# Distribution des r√©gimes\n",
    "print(\"üìä Distribution des r√©gimes d√©tect√©s:\")\n",
    "regime_counts = regime_series.value_counts(normalize=True) * 100\n",
    "for regime, pct in regime_counts.items():\n",
    "    print(f\"   {regime.name}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ D√©finition des strat√©gies √† comparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 2 strat√©gies configur√©es:\n",
      "   - Baseline (Fixed): Fixed parameters (baseline)\n",
      "   - Regime Adaptive: Regime-based adaptation (envelope_std)\n"
     ]
    }
   ],
   "source": [
    "# Liste des adaptateurs √† tester\n",
    "adapters = {\n",
    "    \"Baseline (Fixed)\": FixedParamsAdapter(params_coin),\n",
    "    \n",
    "    \"Regime Adaptive\": RegimeBasedAdapter(\n",
    "        base_params=params_coin,\n",
    "        regime_series=regime_series,\n",
    "        regime_params=DEFAULT_PARAMS,\n",
    "        multipliers={'envelope_std': True},\n",
    "        base_std=0.10\n",
    "    ),\n",
    "    \n",
    "    # Ajouter d'autres configurations ici...\n",
    "    # \"Conservative\": RegimeBasedAdapter(..., base_std=0.08),\n",
    "    # \"Aggressive\": RegimeBasedAdapter(..., base_std=0.12),\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ {len(adapters)} strat√©gies configur√©es:\")\n",
    "for name, adapter in adapters.items():\n",
    "    print(f\"   - {name}: {adapter.get_description()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Ex√©cution des backtests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Ex√©cution des backtests...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚ñ∂ Baseline (Fixed)\n",
      "--------------------------------------------------------------------------------\n",
      "   Wallet final: $1304.99 (+30.50%)\n",
      "   Trades: 558\n",
      "\n",
      "‚ñ∂ Regime Adaptive\n",
      "--------------------------------------------------------------------------------\n",
      "   Wallet final: $1463.38 (+46.34%)\n",
      "   Trades: 564\n",
      "\n",
      "================================================================================\n",
      "‚úÖ Tous les backtests termin√©s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparateur\n",
    "comparator = BacktestComparator(initial_wallet=1000)\n",
    "\n",
    "# Param√®tres communs\n",
    "backtest_params = {\n",
    "    \"initial_wallet\": 1000,\n",
    "    \"leverage\": BACKTEST_LEVERAGE,\n",
    "    \"maker_fee\": 0.0002,\n",
    "    \"taker_fee\": 0.0006,\n",
    "    \"stop_loss\": 0.25,\n",
    "    \"reinvest\": True,\n",
    "    \"liquidation\": True,\n",
    "    \"risk_mode\": \"scaling\",\n",
    "}\n",
    "\n",
    "# Ex√©cuter tous les backtests\n",
    "print(\"\\nüöÄ Ex√©cution des backtests...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for strategy_name, adapter in adapters.items():\n",
    "    print(f\"\\n‚ñ∂ {strategy_name}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Initialiser la strat√©gie\n",
    "    strategy = EnvelopeMulti_v2(\n",
    "        df_list=df_list,\n",
    "        oldest_pair=oldest_pair,\n",
    "        type=[\"long\", \"short\"],\n",
    "        params=params_coin\n",
    "    )\n",
    "    \n",
    "    # Pr√©parer les indicateurs\n",
    "    strategy.populate_indicators()\n",
    "    strategy.populate_buy_sell()\n",
    "    \n",
    "    # Ex√©cuter avec l'adaptateur\n",
    "    result = strategy.run_backtest(\n",
    "        **backtest_params,\n",
    "        params_adapter=adapter  # üîë Adaptation dynamique\n",
    "    )\n",
    "    \n",
    "    # Extraire trades et days du r√©sultat\n",
    "    df_trades = result['trades']\n",
    "    df_days = result['days']\n",
    "    \n",
    "    # Ajouter au comparateur\n",
    "    comparator.add_backtest(\n",
    "        name=strategy_name,\n",
    "        df_trades=df_trades,\n",
    "        df_days=df_days,\n",
    "        metadata={\n",
    "            \"adapter\": adapter.get_description(),\n",
    "            \"leverage\": BACKTEST_LEVERAGE,\n",
    "            \"period\": f\"{START_DATE} to {END_DATE}\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Afficher r√©sultat rapide\n",
    "    final_wallet = df_days['wallet'].iloc[-1] if len(df_days) > 0 else 1000\n",
    "    perf = ((final_wallet / 1000) - 1) * 100\n",
    "    print(f\"   Wallet final: ${final_wallet:.2f} ({perf:+.2f}%)\")\n",
    "    print(f\"   Trades: {len(df_trades)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Tous les backtests termin√©s\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Comparaison et recommandation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîç COMPARAISON DES BACKTESTS\n",
      "================================================================================\n",
      "        Strategy  Final Wallet  Total Perf (%)  Sharpe Ratio  Max DD (%)  Win Rate (%)  N Trades  Avg PnL (%)  Max Win (%)  Max Loss (%)  Total Fees  Avg Exposition  Avg Long Expo  Avg Short Expo  Avg Duration (h)\n",
      "Baseline (Fixed)   1304.987961       30.498796      2.240645   -3.543498     69.892473       558     1.122595    10.012105     -9.630526   13.426143       11.655207       7.367617        4.287591          5.044803\n",
      " Regime Adaptive   1463.375803       46.337580      2.353036   -5.026671     65.425532       564     1.462663    11.084561     -9.630526   14.473617       12.114592       7.762609        4.351984          4.950355\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ RECOMMANDATION: Regime Adaptive\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# G√©n√©rer le rapport comparatif\n",
    "comparator.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap significativit√©",
    "def bootstrap_sharpe_difference(df_days_adaptive, df_days_fixed, n_bootstrap=1000):",
    "    returns_adaptive = df_days_adaptive['wallet'].pct_change().dropna()",
    "    returns_fixed = df_days_fixed['wallet'].pct_change().dropna()",
    "    min_len = min(len(returns_adaptive), len(returns_fixed))",
    "    returns_adaptive = returns_adaptive.iloc[:min_len]",
    "    returns_fixed = returns_fixed.iloc[:min_len]",
    "    sharpe_diffs = []",
    "    for _ in range(n_bootstrap):",
    "        idx = np.random.choice(len(returns_adaptive), len(returns_adaptive), replace=True)",
    "        sample_a = returns_adaptive.iloc[idx]",
    "        sample_f = returns_fixed.iloc[idx]",
    "        sharpe_a = sample_a.mean() / sample_a.std() * np.sqrt(252*24) if sample_a.std() > 0 else 0",
    "        sharpe_f = sample_f.mean() / sample_f.std() * np.sqrt(252*24) if sample_f.std() > 0 else 0",
    "        sharpe_diffs.append(sharpe_a - sharpe_f)",
    "    sharpe_diffs = np.array(sharpe_diffs)",
    "    uplift = np.mean(sharpe_diffs)",
    "    ci_lower = np.percentile(sharpe_diffs, 2.5)",
    "    ci_upper = np.percentile(sharpe_diffs, 97.5)",
    "    is_significant = ci_lower > 0",
    "    return uplift, ci_lower, ci_upper, is_significant",
    "",
    "bt_fixed = [bt for bt in comparator.backtests if \"Fixed\" in bt.name][0]",
    "bt_adaptive = [bt for bt in comparator.backtests if \"Adaptive\" in bt.name][0]",
    "",
    "uplift, ci_low, ci_high, is_sig = bootstrap_sharpe_difference(bt_adaptive.df_days, bt_fixed.df_days, 1000)",
    "",
    "print(\"üìä BOOTSTRAP SIGNIFICATIVIT√â\")",
    "print(\"=\" * 80)",
    "print(f\"Uplift Sharpe: {uplift:+.3f}\")",
    "print(f\"IC 95%: [{ci_low:+.3f}, {ci_high:+.3f}]\")",
    "print(f\"Significatif: {'‚úÖ OUI' if is_sig else '‚ùå NON'}\")",
    "if is_sig:",
    "    print(\"‚úÖ L'adaptation am√©liore significativement le Sharpe\")",
    "else:",
    "    print(\"‚ö†Ô∏è  Pas de preuve statistique\")",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par classe",
    "print(\"\\nüìà ANALYSE PAR CLASSE\")",
    "print(\"=\" * 80)",
    "",
    "results = []",
    "for pair in params_coin.keys():",
    "    df_tf = bt_fixed.df_trades[bt_fixed.df_trades['pair'] == pair].copy()",
    "    df_ta = bt_adaptive.df_trades[bt_adaptive.df_trades['pair'] == pair].copy()",
    "    for df in [df_tf, df_ta]:",
    "        if len(df) > 0 and 'trade_result' not in df.columns:",
    "            df['trade_result'] = df[\"close_trade_size\"] - df[\"open_trade_size\"] - df[\"open_fee\"] - df[\"close_fee\"]",
    "    pnl_f = df_tf['trade_result'].sum() if len(df_tf) > 0 else 0",
    "    pnl_a = df_ta['trade_result'].sum() if len(df_ta) > 0 else 0",
    "    results.append({'pair': pair, 'class': PAIR_CLASSES[pair], 'delta_pnl': pnl_a - pnl_f})",
    "",
    "df_res = pd.DataFrame(results).groupby('class')['delta_pnl'].mean().round(2)",
    "print(df_res)",
    "print(f\"\\n‚úÖ Meilleure: {df_res.idxmax()} (+${df_res.max():.2f})\")",
    "print(f\"‚ö†Ô∏è  Pire: {df_res.idxmin()} ({df_res.min():+.2f}$)\")",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "",
    "data = []",
    "for pair in params_coin.keys():",
    "    df_ta = bt_adaptive.df_trades[bt_adaptive.df_trades['pair'] == pair].copy()",
    "    df_tf = bt_fixed.df_trades[bt_fixed.df_trades['pair'] == pair].copy()",
    "    for df in [df_ta, df_tf]:",
    "        if len(df) > 0 and 'trade_result' not in df.columns:",
    "            df['trade_result'] = df[\"close_trade_size\"] - df[\"open_trade_size\"] - df[\"open_fee\"] - df[\"close_fee\"]",
    "    if len(df_ta) > 0:",
    "        df_ta['date'] = pd.to_datetime(df_ta['open_date'])",
    "        df_ta['regime'] = df_ta['date'].map(lambda x: regime_series.asof(x))",
    "    if len(df_tf) > 0:",
    "        df_tf['date'] = pd.to_datetime(df_tf['open_date'])",
    "        df_tf['regime'] = df_tf['date'].map(lambda x: regime_series.asof(x))",
    "    for reg in ['BULL', 'BEAR', 'RECOVERY']:",
    "        if len(df_ta) > 0:",
    "            pnl_a = df_ta[df_ta['regime'].astype(str).str.contains(reg, na=False)]['trade_result'].sum()",
    "            dates = df_ta[df_ta['regime'].astype(str).str.contains(reg, na=False)]['date']",
    "            pnl_f = df_tf[df_tf['date'].isin(dates)]['trade_result'].sum() if len(df_tf) > 0 else 0",
    "            data.append({'class': PAIR_CLASSES[pair], 'regime': reg, 'delta': pnl_a - pnl_f})",
    "",
    "df_h = pd.DataFrame(data).groupby(['class', 'regime'])['delta'].sum().unstack(fill_value=0)",
    "fig, ax = plt.subplots(figsize=(10, 6))",
    "sns.heatmap(df_h, annot=True, fmt=\".1f\", cmap='RdYlGn', center=0, ax=ax)",
    "ax.set_title('Delta PnL par Classe √ó R√©gime')",
    "plt.tight_layout()",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bt_fixed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m params_coin.keys():\n\u001b[32m      9\u001b[39m     pair_class = PAIR_CLASSES[pair]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     df_trades_fixed = \u001b[43mbt_fixed\u001b[49m.df_trades[bt_fixed.df_trades[\u001b[33m'\u001b[39m\u001b[33mpair\u001b[39m\u001b[33m'\u001b[39m] == pair].copy()\n\u001b[32m     12\u001b[39m     df_trades_adaptive = bt_adaptive.df_trades[bt_adaptive.df_trades[\u001b[33m'\u001b[39m\u001b[33mpair\u001b[39m\u001b[33m'\u001b[39m] == pair].copy()\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Add trade_result\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'bt_fixed' is not defined"
     ]
    }
   ],
   "source": [
    "# Heatmap: Delta PnL par classe √ó r√©gime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Heatmap data: class √ó regime\n",
    "heatmap_data = []\n",
    "\n",
    "for pair in params_coin.keys():\n",
    "    pair_class = PAIR_CLASSES[pair]\n",
    "    \n",
    "    df_trades_fixed = bt_fixed.df_trades[bt_fixed.df_trades['pair'] == pair].copy()\n",
    "    df_trades_adaptive = bt_adaptive.df_trades[bt_adaptive.df_trades['pair'] == pair].copy()\n",
    "    \n",
    "    # Add trade_result\n",
    "    for df in [df_trades_fixed, df_trades_adaptive]:\n",
    "        if len(df) > 0 and 'trade_result' not in df.columns:\n",
    "            df['trade_result'] = (\n",
    "                df[\"close_trade_size\"] - df[\"open_trade_size\"] - \n",
    "                df[\"open_fee\"] - df[\"close_fee\"]\n",
    "            )\n",
    "    \n",
    "    # Map regime to trades\n",
    "    if len(df_trades_adaptive) > 0:\n",
    "        df_trades_adaptive['date'] = pd.to_datetime(df_trades_adaptive['open_date'])\n",
    "        df_trades_adaptive['regime'] = df_trades_adaptive['date'].map(\n",
    "            lambda x: regime_series.asof(x) if x in regime_series.index or any(regime_series.index <= x) else None\n",
    "        )\n",
    "        \n",
    "    if len(df_trades_fixed) > 0:\n",
    "        df_trades_fixed['date'] = pd.to_datetime(df_trades_fixed['open_date'])\n",
    "        df_trades_fixed['regime'] = df_trades_fixed['date'].map(\n",
    "            lambda x: regime_series.asof(x) if x in regime_series.index or any(regime_series.index <= x) else None\n",
    "        )\n",
    "    \n",
    "    # Calculate PnL by regime\n",
    "    for regime_name in ['BULL', 'BEAR', 'RECOVERY']:\n",
    "        if len(df_trades_adaptive) > 0:\n",
    "            pnl_adaptive = df_trades_adaptive[df_trades_adaptive['regime'].astype(str).str.contains(regime_name, na=False)]['trade_result'].sum()\n",
    "            \n",
    "            # Get matching dates from adaptive\n",
    "            matching_dates = df_trades_adaptive[df_trades_adaptive['regime'].astype(str).str.contains(regime_name, na=False)]['date']\n",
    "            pnl_fixed = df_trades_fixed[df_trades_fixed['date'].isin(matching_dates)]['trade_result'].sum() if len(df_trades_fixed) > 0 and 'trade_result' in df_trades_fixed.columns else 0\n",
    "            \n",
    "            heatmap_data.append({\n",
    "                'class': pair_class,\n",
    "                'regime': regime_name,\n",
    "                'delta_pnl': pnl_adaptive - pnl_fixed,\n",
    "            })\n",
    "\n",
    "df_heatmap = pd.DataFrame(heatmap_data)\n",
    "df_heatmap_pivot = df_heatmap.groupby(['class', 'regime'])['delta_pnl'].sum().unstack(fill_value=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.heatmap(df_heatmap_pivot, annot=True, fmt=\".1f\", cmap='RdYlGn', center=0, \n",
    "            cbar_kws={'label': 'Delta PnL ($)'}, ax=ax)\n",
    "ax.set_title('Delta PnL (Adaptive - Fixed) par Classe √ó R√©gime', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('R√©gime de march√©')\n",
    "ax.set_ylabel('Classe d\\'actifs')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Interpr√©tation:\")\n",
    "print(\"   - Vert: Adaptive performe mieux\")\n",
    "print(\"   - Rouge: Fixed performe mieux\")\n",
    "print(\"   - Identifier les classes/r√©gimes o√π l'adaptation est b√©n√©fique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par classe d'actifs\n",
    "print(\"\\nüìà ANALYSE PAR CLASSE D'ACTIFS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculer m√©triques par paire pour chaque strat√©gie\n",
    "results_by_pair = []\n",
    "\n",
    "for pair in params_coin.keys():\n",
    "    # Filter trades for this pair\n",
    "    df_trades_fixed = bt_fixed.df_trades[bt_fixed.df_trades['pair'] == pair].copy()\n",
    "    df_trades_adaptive = bt_adaptive.df_trades[bt_adaptive.df_trades['pair'] == pair].copy()\n",
    "    \n",
    "    # Calculate trade_result if absent\n",
    "    for df in [df_trades_fixed, df_trades_adaptive]:\n",
    "        if len(df) > 0 and 'trade_result' not in df.columns:\n",
    "            df['trade_result'] = (\n",
    "                df[\"close_trade_size\"] -\n",
    "                df[\"open_trade_size\"] -\n",
    "                df[\"open_fee\"] -\n",
    "                df[\"close_fee\"]\n",
    "            )\n",
    "    \n",
    "    # M√©triques\n",
    "    n_trades_fixed = len(df_trades_fixed)\n",
    "    n_trades_adaptive = len(df_trades_adaptive)\n",
    "    \n",
    "    if n_trades_fixed > 0:\n",
    "        wr_fixed = (df_trades_fixed['trade_result'] > 0).mean() * 100\n",
    "        pnl_fixed = df_trades_fixed['trade_result'].sum()\n",
    "    else:\n",
    "        wr_fixed = 0\n",
    "        pnl_fixed = 0\n",
    "        \n",
    "    if n_trades_adaptive > 0:\n",
    "        wr_adaptive = (df_trades_adaptive['trade_result'] > 0).mean() * 100\n",
    "        pnl_adaptive = df_trades_adaptive['trade_result'].sum()\n",
    "    else:\n",
    "        wr_adaptive = 0\n",
    "        pnl_adaptive = 0\n",
    "    \n",
    "    results_by_pair.append({\n",
    "        'pair': pair,\n",
    "        'class': PAIR_CLASSES[pair],\n",
    "        'n_trades_fixed': n_trades_fixed,\n",
    "        'n_trades_adaptive': n_trades_adaptive,\n",
    "        'wr_fixed': wr_fixed,\n",
    "        'wr_adaptive': wr_adaptive,\n",
    "        'pnl_fixed': pnl_fixed,\n",
    "        'pnl_adaptive': pnl_adaptive,\n",
    "        'delta_pnl': pnl_adaptive - pnl_fixed,\n",
    "        'delta_wr': wr_adaptive - wr_fixed,\n",
    "    })\n",
    "\n",
    "df_pair_analysis = pd.DataFrame(results_by_pair)\n",
    "\n",
    "# Aggregate by class\n",
    "df_class_analysis = df_pair_analysis.groupby('class').agg({\n",
    "    'delta_pnl': 'mean',\n",
    "    'delta_wr': 'mean',\n",
    "    'n_trades_adaptive': 'sum',\n",
    "}).round(2)\n",
    "\n",
    "print(f\"\\nDelta performance (Adaptive - Fixed) par classe:\")\n",
    "print(df_class_analysis.to_string())\n",
    "\n",
    "# Identify best/worst classes\n",
    "best_class = df_class_analysis['delta_pnl'].idxmax()\n",
    "worst_class = df_class_analysis['delta_pnl'].idxmin()\n",
    "\n",
    "print(f\"\\n‚úÖ Meilleure classe avec Adaptive: {best_class} (+${df_class_analysis.loc[best_class, 'delta_pnl']:.2f})\")\n",
    "print(f\"‚ö†Ô∏è  Pire classe avec Adaptive: {worst_class} ({df_class_analysis.loc[worst_class, 'delta_pnl']:+.2f}$)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction bootstrap pour tester significativit√©\n",
    "def bootstrap_sharpe_difference(df_days_adaptive, df_days_fixed, n_bootstrap=1000):\n",
    "    \"\"\"\n",
    "    Bootstrap test pour v√©rifier si Adaptive > Fixed avec IC95%\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (uplift_moyen, ci_lower, ci_upper, is_significant)\n",
    "    \"\"\"\n",
    "    # Calculer returns\n",
    "    returns_adaptive = df_days_adaptive['wallet'].pct_change().dropna()\n",
    "    returns_fixed = df_days_fixed['wallet'].pct_change().dropna()\n",
    "    \n",
    "    # Align lengths\n",
    "    min_len = min(len(returns_adaptive), len(returns_fixed))\n",
    "    returns_adaptive = returns_adaptive.iloc[:min_len]\n",
    "    returns_fixed = returns_fixed.iloc[:min_len]\n",
    "    \n",
    "    sharpe_diffs = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        # Resample avec remplacement\n",
    "        idx = np.random.choice(len(returns_adaptive), len(returns_adaptive), replace=True)\n",
    "        \n",
    "        sample_adaptive = returns_adaptive.iloc[idx]\n",
    "        sample_fixed = returns_fixed.iloc[idx]\n",
    "        \n",
    "        # Sharpe des samples\n",
    "        sharpe_a = sample_adaptive.mean() / sample_adaptive.std() * np.sqrt(252*24) if sample_adaptive.std() > 0 else 0\n",
    "        sharpe_f = sample_fixed.mean() / sample_fixed.std() * np.sqrt(252*24) if sample_fixed.std() > 0 else 0\n",
    "        \n",
    "        sharpe_diffs.append(sharpe_a - sharpe_f)\n",
    "    \n",
    "    sharpe_diffs = np.array(sharpe_diffs)\n",
    "    uplift = np.mean(sharpe_diffs)\n",
    "    ci_lower = np.percentile(sharpe_diffs, 2.5)\n",
    "    ci_upper = np.percentile(sharpe_diffs, 97.5)\n",
    "    is_significant = ci_lower > 0  # Significatif si borne basse > 0\n",
    "    \n",
    "    return uplift, ci_lower, ci_upper, is_significant\n",
    "\n",
    "# R√©cup√©rer les r√©sultats par strat√©gie\n",
    "bt_fixed = [bt for bt in comparator.backtests if \"Fixed\" in bt.name][0]\n",
    "bt_adaptive = [bt for bt in comparator.backtests if \"Adaptive\" in bt.name][0]\n",
    "\n",
    "# Test bootstrap global\n",
    "uplift, ci_low, ci_high, is_sig = bootstrap_sharpe_difference(\n",
    "    bt_adaptive.df_days, \n",
    "    bt_fixed.df_days, \n",
    "    n_bootstrap=1000\n",
    ")\n",
    "\n",
    "print(\"üìä BOOTSTRAP SIGNIFICATIVIT√â (1000 it√©rations)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nUplift Sharpe (Adaptive - Fixed):\")\n",
    "print(f\"   Moyenne: {uplift:+.3f}\")\n",
    "print(f\"   IC 95%: [{ci_low:+.3f}, {ci_high:+.3f}]\")\n",
    "print(f\"   Significatif: {'‚úÖ OUI' if is_sig else '‚ùå NON'} (borne basse > 0)\")\n",
    "\n",
    "if is_sig:\n",
    "    print(f\"\\n‚úÖ Conclusion: L'adaptation aux r√©gimes am√©liore significativement le Sharpe Ratio\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Conclusion: Pas de preuve statistique que l'adaptation am√©liore le Sharpe\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir le classement par m√©trique sp√©cifique\n",
    "print(\"\\nüìä Top strat√©gies par Sharpe Ratio:\")\n",
    "print(comparator.rank('Sharpe Ratio')[['Strategy', 'Sharpe Ratio', 'Total Perf (%)', 'Max DD (%)']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voir le score composite (pond√©r√©)\n",
    "print(\"\\nüèÜ Scores composites (pond√©ration automatique):\")\n",
    "scored = comparator.score()\n",
    "print(scored[['Strategy', 'Score', 'Total Perf (%)', 'Sharpe Ratio', 'Max DD (%)']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les r√©sultats\n",
    "output_path = \"backtest_comparison_results.csv\"\n",
    "comparator.save_comparison(output_path)\n",
    "print(f\"\\nüíæ R√©sultats complets sauvegard√©s: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Analyse d√©taill√©e (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser l'√©volution du wallet pour chaque strat√©gie\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for bt in comparator.backtests:\n",
    "    df_days = bt.df_days.copy()\n",
    "    if len(df_days) > 0:\n",
    "        df_days['date'] = pd.to_datetime(df_days['day'])\n",
    "        plt.plot(df_days['date'], df_days['wallet'], label=bt.name, linewidth=2)\n",
    "\n",
    "plt.axhline(y=1000, color='gray', linestyle='--', alpha=0.5, label='Initial Wallet')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Wallet ($)')\n",
    "plt.title('Comparaison de l\\'√©volution du wallet')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Conclusion\n",
    "\n",
    "- Le tableau comparatif montre toutes les m√©triques cl√©s\n",
    "- La recommandation est bas√©e sur un score composite pond√©r√©\n",
    "- Vous pouvez facilement ajouter de nouvelles strat√©gies dans la section 2Ô∏è‚É£\n",
    "- Les r√©sultats sont automatiquement sauvegard√©s en CSV\n",
    "\n",
    "**Next steps:**\n",
    "1. Ajuster les pond√©rations du score selon vos priorit√©s\n",
    "2. Tester sur diff√©rentes p√©riodes\n",
    "3. Cr√©er des adaptateurs custom avec votre propre logique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}